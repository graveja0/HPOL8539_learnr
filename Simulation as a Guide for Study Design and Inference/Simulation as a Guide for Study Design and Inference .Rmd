---
title: "Simulation as a Guide for Study Design and Inference"
subtitle: "HPOL8539"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    css: "css/style.css"
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
# load packages
library(learnr)
library(gradethis)
library(sortable)
library(tidyverse)
library(learnrhash) #devtools::install_github("rundel/learnrhash")
library(showtext)
library(googlesheets4)
library(mcreplicate)
library(knitr)
library(hrbrthemes)
#devtools::install_github("graveja0/HPOL8539PKG")
#library(HPOL8539PKG)
# devtools::load_all("../../HPOL8539PKG")


# don't echo chunks
knitr::opts_chunk$set(echo = FALSE)

# apply theme to ggplot
ggplot2::theme_set(theme_bw())

plot_sampling_distribution <- function(x,truth) {
  d <- density(x)
  p_df <- as_tibble(cbind(x = d$x, density = d$y))
  p_df %>%
    ggplot(aes(x = x, y = density)) + geom_line() +
    #hrbrthemes::theme_ipsum() +
    labs(x = "Estimate", y = "Density") +
    geom_vline(aes(xintercept = truth)) +
    annotate("text",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue("  \tMean: {formatC(mean(x),digits = 3, format='f')}\n   SD: {formatC(sd(x),digits = 3, format = 'f')}"), hjust = 0)
}

plot_cis <- function(x, K, truth) {
  res <- x %>% bind_rows(.id = "m") %>%
    as_tibble() %>%
    mutate(m = factor(m)) %>%
    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%
    mutate(truth = truth) %>%
    rowwise() %>%
    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%
    ungroup() %>%
    mutate(color = ifelse(covered ==1 , "","Rejected"))
  
  K = sample(res$m,100, replace =TRUE)
  res %>%
    filter(m %in% K) %>%
    ggplot() +
    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +
    #theme_ipsum() +
    scale_y_discrete(breaks = NULL) +
    geom_vline(aes(xintercept = truth)) +
    labs(title= glue("Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates"),
         y= "Sampling Iteration",x = "Estimate",
         subtitle= glue("{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth")) +
    scale_colour_manual(values = c("black","red")) +
    theme(legend.position = "none")
}


```

## Introduction

The goal of this exercise is to familiarize you with how to use simulation to help guide your choice of estimators and inference for policy and program evaluation. 

## Exercise 1: Simulating From a Distribution

Our first objective is to parameterize and execute the simplest possible simulation:

- Sample size is $N=1,000$ individuals indexed by $i$. 
- The simulated variable $X_i$ is normally distributed with mean 2 and standard deviation 0.5, i.e., $X_i \sim N(2,0.5)$.

We will proceed along four steps:

1. Parameterize the problem.
2. Define a data generation function.
3. Define and apply an estimation function.
4. Define and apply a discriminator function. 

### Step 1: Parameterize the Problem

```{r simple1}
#| echo: true
#| exercise.eval: false
#| exercise: true
#| exercise.lines: 8
params =
  list(
    N = 1000, 
    mean_x_i = 2,
    sd_x_i = 0.5
  )
params
```

### Step 2: Define a Data Generation Process 

Our next objective is to write a very basic data generation function that takes as its input the parameter list created above, and spits out the simulated value of $X_i$ based on those parameters. 

Note that the `rnorm()` command is R's way of simulating from a normal distribution. 

Go ahead and execute the ``dgp()`` function with the supplied parameters below.

```{r simple1_dgp, exercise.setup = "simple1"}
#| echo: true
#| exercise.eval: false
#| exercise: true
#| exercise.lines: 10

# Simulate a data generation process (dgp)
dgp = function(params) {
  with(params,{
    x_i = rnorm(N, mean_x_i, sd_x_i)
    return(x_i)
  })
}

params %>% 
  dgp()

```

#### Structure Output as a Data Frame

You'll notice that the output is rather .... messy. Let's restructure our data generation code so that it outputs as a data frame / tibble, rather than a simple vector. 

```{r simple1_dgp3, exercise.setup = "simple1_dgp"}
#| echo: true
#| exercise: true
#| exercise-setup: simple1_dgp
#| exercise.lines: 12

dgp_df =function(params) {
  with(params,{
    df =
      tibble(
        x_i = rnorm(N, mean_x_i, sd_x_i)
      )
    return(df)
  })
}

params %>% dgp_df()
```


### Step 3: Define and Apply an Estimation Function

Now lets suppose we want to estimate the expected value (mean) of $X_i$. For an estimator this basic we could, of course, simply summarize directly. However, to allow for more complex estimators we'll define it in a function.

Below we define a function that takes as its input a data frame (``df``). We then take the mean of ``x_i``:

```{r simple1_est1, exercise.setup = "simple1_dgp3"}
#| echo: true
#| exercise: true
#| exercise-setup: simple1_dgp
#| exercise.lines: 11

estimator_fn =function(df) {
  out =
    df %>% 
      summarise(mean_x_i = mean(x_i))
  return(out)
}

params %>% 
  dgp_df() %>% 
  estimator_fn()

```

Next, suppose we want to adapt our estimator. Instead of the mean, we want to estimate the mean plus 1. We can simply adapt our estimator function accordingly:

```{r simple1_est2, exercise.setup = "simple1_est1"}
#| echo: true
#| exercise: true
#| exercise-setup: simple1_dgp
#| exercise.lines: 11

estimator_fn_alt =function(df) {
  out =
    df %>% 
      summarise(mean_x_i = mean(x_i) + 1)
  return(out)
}

params %>% 
  dgp_df() %>% 
  estimator_fn_alt()


```

We'll skip step 4 ("Define and Apply a Discriminator Function") for now and next adapt and expand the above for an outcome ($Y_i$) that is a function of $X_i$ and a treatment effect. 

## Exercise 2: Basic Regression

Our next exercise will simulate an outcome ($Y_i$) based on a defined data generation process. Let's define the data generation process in terms of a binary treatment indicator $D_i$, a continuous patient-level attribute ($X_i \sim N(2,0.5)$, as above) , and an idiosyncratic error term $\epsilon_i \sim N(0,1)$:


$$
\begin{aligned}
Y_i &= \beta X_i + \tau D_i + \epsilon_i \\
 & = 1 \cdot X_i + 0.5 \cdot D_i + \epsilon_i
\end{aligned}
$$

In R, normally distributed variables are sampled using `rnorm()`, while binary variables can be sampled using `rbinom()`. Let's suppose 50% of the sample is treated, in expectation. 

We will now re-parametrize and define a data generation function based on the above:

### Step 1: Parameterize the Problem

```{r basicreg1_param}
#| echo: true
#| exercise: true
#| exercise.lines: 10
#| 
params =list(
  N = 1000,
  mean_x_i = 2,
  sd_x_i = 0.5,
  pr_Tx = 0.5,
  beta = 1,
  tau = 0.5,
  sigma_sq_epsilon = 1
)

params 

```

### Step 2: Define a Data Generation Process Function

```{r basicreg1_dgp, exercise.setup = "basicreg1_param"}
#| echo: true
#| exercise: true
#| exercise.lines: 16

dgp_df =function(params) {
  with(params,{
    df =
      tibble(
        x_i = rnorm(N, mean_x_i, sd_x_i),
        d_i = rbinom(N, size = 1, prob = pr_Tx),
        epsilon_i = rnorm(N, mean = 0, sd = sigma_sq_epsilon)
      ) %>% 
      mutate(y_i = beta * x_i + tau * d_i + epsilon_i)
    return(df)
  })
}

params %>% 
  dgp_df()
```

### Step 3: Define and Apply an Estimation Function

Next, suppose we are interested in estimating $\tau$, the coefficient on being in the treatment group. In that case there is a relatively straightforward mapping between our **quantity of interest**, i.e., $\tau$ and what we can obtain directly from an ordinary least squares (OLS) regression (i.e., the **estimator**) of $Y_i$ on $X_i$ and $D_i$. In R, an OLS regression can be fit using the command `lm()`.


```{r basicreg1_est, exercise.setup = "basicreg1_dgp"}
#| echo: true
#| exercise: true
#| exercise.lines: 15

estimator_fn = function(df) {
  out =
    df %>% 
      lm(y_i ~ x_i + d_i, data = .)
  return(out)
}

fit1 = 
  params %>% # Step 1: Parameterize the problem
    dgp_df() %>%  # Step 2: Define the data generation process
    estimator_fn() # Step 3: Apply the estimator
fit1 
```

### Step 4: Define and Apply a Discriminator Function

Above, we noted that the parameter of interest is $\tau$, the coefficient on the binary treatment indicator. We'll now define a "discriminator" function that plucks out this parameter of interest.

Note that this function takes as its input a fitted estimation object, not a data frame. 

```{r basicreg1_disc1, exercise.setup = "basicreg1_est"}
#| echo: true
#| exercise: true
#| exercise.lines: 15

disc_fn = function(fit) {
  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object
  out =fit_ %>% 
    filter(term=="d_i") %>% 
    pull(estimate)
  
  return(out)
}

# First, take a look at what tidy() does. 
broom::tidy(fit1)

# Next, apply the discriminator function to the estimated regression
disc_fn(fit1)


```

We can now pull everything together into one code pipe to complete the full four-step process. Each time we run it, we simulate a new dataset based on the defined parameters, estimate $\tau$, then pull out our estimate of $\tau$ from the OLS regression: 

```{r basicreg1_disc2, exercise.setup = "basicreg1_disc1"}
#| echo: true
#| exercise: true
#| exercise.lines: 18

# Run it once...
params %>% 
  dgp_df() %>% 
    estimator_fn() %>% 
      disc_fn()
      
# Run it again...
params %>% 
  dgp_df() %>% 
    estimator_fn() %>% 
      disc_fn()
      
# Run it a third time!    
params %>% 
  dgp_df() %>% 
    estimator_fn() %>% 
      disc_fn()
```



## Exercise 3: Monte Carlo Simulation

We now have the tools and functions in place to simulate, estimate, and draw our parameter of interest. However, what if we want to understand properties of our estimator? That is, is it unbiased (i.e., estimate the underlying "truth" accurately)? Alternatively, we might be concerned about issues of inference. For example, if we estimate a basic linear regression model without accounting for heteroskedasticity, will we have a false discovery rate of 5%?

To answer these types of questions it is often useful to conduct a full monte carlo simulation. The basic steps are simple:

1. Generate the data, estimate the model, and pull out the parameter of interest $M$ times. 
2. Look at the distribution of $M$ parameters. 

### Sampling Distribution of the OLS estimator 

```{r basicreg1_mcgen, exercise.setup = "basicreg1_disc1"}
#| echo: true
#| exercise: true
#| exercise.lines: 20

M = 1000

res_sampdist <- c() # we start with a basic (empty) object. 

# Loop over the generation, estimation, discrimination process
# M times, each time storing the result
for (m in 1:M) {
  # We're just going to append the result on the end of the result opbject
  res_sampdist <- 
    c(res_sampdist, 
      # You've seen all this before ... 
      params %>%
        dgp_df() %>%
          estimator_fn() %>%
            disc_fn()
  )
}
plot_sampling_distribution(res_sampdist,truth=params$tau)

```

### Aside: Loops using `map()`

The loop structure above is totally fine to use, however it results in rather clunky code. An option I highly recommend is the `purrr` package in R, which simplifies loops into a single command called `map()`.

The basic structure is that you supply `map()` with a vector of things to "loop" over, which in this case is just the numbers 1 through $M$ (i.e., ```for (m in 1:M)``` in the loop code above). Just like in the `for` loop above, each time we apply the generate, estimate, and discriminate functions we created earlier.  We can even simplify this three-step process within its own "meta" function that does everything at once. 

The below code first defines a single function that takes as its input the parameters you're generating data on. The function generates data based on it, estimates the OLS model, and pulls out the $\hat \tau$ coefficient, all using the functions we defined earlier. 

Next, the code uses `map()` to replicate this process $M=1,000$ times, and stores the results in a vector called `res_sampdist`. We now have reduced the loop code above to a single line of code. 

```{r basicreg1_mapex, exercise.setup = "basicreg1_disc1"}
#| echo: true
#| exercise: true
#| exercise.lines: 14

generate_estimate_discriminate <- function(params) {
      params %>%
        dgp_df() %>%
          estimator_fn() %>%
            disc_fn()
}

M = 1000
res_sampdist <- 
  1:M %>% 
  map_dbl(~generate_estimate_discriminate(params))

plot_sampling_distribution(res_sampdist, truth = params$tau)

```

### Aside 2: Updating Parameters 

Now suppose we want to study some property of the estimator. For example, in the parameter definition above we set the sample size as 1,000. What if we want to explore the sampling distribution with a sample size of 100? 

This is easy to do using a command called `modifyList()`

```{r basicreg1_mapex2, exercise.setup = "basicreg1_mapex"}
#| echo: true
#| exercise: true
#| exercise.lines: 8

# Let's change the sample size from 1,000 to 100 

updated_params <- modifyList(params,list(N=100))
updated_params 

```

## Exercise 4: Type I Error and Confidence Intervals 

Our next simulation exercise will pursue a different objective: to understand whether a given approach to estimation and inference yield the expected Type I error (i.e., failinig to reject the null when it is not true). 

We will do so by extracting out the 95% confidence intervals after a regression. 

Let's first package up steps 1-3 (parameterize, DGP, and estimate) into one exercise:

```{r ci_steps1to3}
#| echo: true
#| exercise: true
#| exercise.lines: 47

##################################
# Step 1: Parameterize the Problem
##################################
params =list(
  N = 1000,
  mean_x_i = 2,
  sd_x_i = 0.5,
  pr_Tx = 0.5,
  beta = 1,
  tau = 0.5,
  sigma_sq_epsilon = 1
)

####################################################
# Step 2: Define a Data Generation Process Function
#####################################################
dgp_df =function(params) {
  with(params,{
    df =
      tibble(
        x_i = rnorm(N, mean_x_i, sd_x_i),
        d_i = rbinom(N, size = 1, prob = pr_Tx),
        epsilon_i = rnorm(N, mean = 0, sd = sigma_sq_epsilon)
      ) %>% 
      mutate(y_i = beta * x_i + tau * d_i + epsilon_i)
    return(df)
  })
}

############################################
# 3. Define and Apply an Estimation Function
#############################################
estimator_fn = function(df) {
  out =
    df %>% 
      lm(y_i ~ x_i + d_i, data = .)
  return(out)
}

fit = 
  params %>% # Step 1: Parameterize the problem
    dgp_df() %>%  # Step 2: Define the data generation process
    estimator_fn() # Step 3: Apply the estimator
fit


```

Next, we will define a discrimination function that asks whether the 95% confidence interval contains the true value of the $\tau$ parameter, and returns this information as a binary variable `contains_truth`. 

```{r ci_steps4, exercise.setup = "ci_steps1to3"}
#| echo: true
#| exercise: true
#| exercise.lines: 17
#| 
disc_fn = function(fit) {
  fit_ =broom::tidy(fit,conf.int = TRUE  )   
  out <- 
    fit_ %>% 
    filter(term == "d_i") %>%
    select(estimate, p.value, conf.low, conf.high) %>% 
    # Is zero within the 95% confidence interval? 
    mutate(contains_truth = as.integer(between(params$tau,conf.low,conf.high)))

  return(out)
}

params %>% # Step 1: Parameterize the problem
    dgp_df() %>%  # Step 2: Define the data generation process
      estimator_fn() %>%  # Step 3: Estimate 
        disc_fn() # Step 4: Pull out what you need
```

Next lets bundle everything up into a single function that runs it all. TEST

```{r ci_disc, exercise.setup = "ci_steps4"}
#| echo: true
#| exercise: true
#| exercise.lines: 10

generate_estimate_discriminate <- function(params) {
  params %>% # Step 1: Parameterize the problem
      dgp_df() %>%  # Step 2: Define the data generation process
        estimator_fn() %>%  # Step 3: Estimate 
          disc_fn() # Step 4: Pull out what you need
}

params %>% 
  generate_estimate_discriminate()

```

Our next step is to repeat this process lots of times via a Monte Carlo simulation. We'll keep the number of Monte Carlo runs small (1000) to speed up computation, but note that in practice we may need to do this thousands of times. 

```{r ci_mc, exercise.setup = "ci_disc"}
#| echo: true
#| exercise: true
#| exercise.lines: 10


# Monte Carlo simulation based on 1000 different realizations of the DGP:
M = 1000
mc_result <- 1:M %>% map_df(~generate_estimate_discriminate(params))

# Take a peek at the output ...
mc_result %>%
  head() %>%
  knitr::kable()

```

Before we plot the results, let's step back and think about what we want to see. We now have a series of results from different Monte Carlo realizations of our defined data generation process. For each simulated dataset, we applied a linear regression estimator and extracted the 95% confidence interval. Each time, we recorded information on whether the interval contained the true value of the parameter, as defined in our parameters. 

Under standard Type I error rates, and if the underlying statistical inference approach is working correctly, we should expect that approximately 95% of our constructed confidence intervals will contain the "truth." 

```{r ci_truth, exercise.setup = "ci_mc"}
#| echo: true
#| exercise: true
#| exercise.lines: 10

mc_result %>% 
  summarise(coverage = mean(contains_truth))

```

Finally, to provide a bit more intuition around what's going on, let's plot the CIs for 100 randomly selected Monte Carlo runs from our results:

```{r ci_plot, exercise.setup = "ci_mc"}
#| echo: true
#| exercise: true
#| exercise.lines: 20

# randomly sample 100 rows
m_ <- sample(1:nrow(mc_result),100, replace = FALSE)

# plot the CIs and color them based on whether or not they contain the truth 
mc_result %>% 
  filter(row_number() %in% m_) %>% 
  mutate(run = row_number()) %>% 
  ggplot() + 
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high, y = run, colour = factor(contains_truth) )) +
  #hrbrthemes::theme_ipsum(base_size=16) +
  scale_y_discrete(breaks = NULL) +
  geom_vline(aes(xintercept = params$tau)) +
  labs(y="Monte Carlo Run", x= "") + 
  theme(legend.position = "none") + 
  theme(axis.title.x = element_text(size=16)) + 
  theme(axis.title.y = element_text(size=16)) 

```

## Exercise 5: Omitted Variables Bias

Our next exercise will set us up nicely for next week's session on panel data methods. We're going to tweak our data generation process a bit to include some unobserved heterogeneity ($u_i$) that is correlated with both treatment and our outcome. Everything else will stay the same as before. 

```{r omb1}
#| echo: true
#| exercise: true
#| exercise.lines: 60

##################################
# Step 1: Parameterize the Problem
##################################
params =list(
  N = 1000,
  mean_x_i = 2,
  sd_x_i = 0.5,
  beta = 1,
  tau = 0.5,
  sigma_sq_epsilon = 1
)

####################################################
# Step 2: Define a Data Generation Process Function
#####################################################
dgp_df_ovb =function(params) {
  with(params,{
    df =
      tibble(
        # Covariate
        x_i = rnorm(N, mean_x_i, sd_x_i),
        # ADD UNOBSERVED HETEROGENEITY TERM
        u_i = rnorm(N, mean = 0, sd = 1)) %>% 
        # Induce correlation between u_i and treatment;
        # higher values of u_i make it more likely you're treated. 
        rowwise() %>% # This allows us to get each value's pr_treated in the line below. 
        mutate(pr_treated = boot::inv.logit(u_i)) %>% 
        ungroup() %>%  # This undoes the rowwise 
        # Treatment indicator
        mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% 
        mutate(epsilon_i = rnorm(N, mean = 0, sd = sigma_sq_epsilon)) %>% 
        # u_i is also in the DGP for y_i 
        mutate(y_i = beta * x_i + tau * d_i + u_i + epsilon_i) %>% 
        # because u_i is unobserved, we strip it from the "observed" data output. 
        select(-u_i)
    return(df)
  })
}

############################################
# 3. Define and Apply an Estimation Function
#############################################
estimator_fn = function(df) {
  out =
    df %>% 
      lm(y_i ~ x_i + d_i, data = .)
  return(out)
}

########################################
# 4. Define the discriminator function 
# (For this exercise we want to extract tau-hat 
# i.e., the coefficient on treated)
########################################
disc_fn = function(fit) {
  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object
  out =fit_ %>% 
    filter(term=="d_i") %>% 
    pull(estimate)
  
  return(out)
}

###############################################
# 5. Define a compound function that executes
# steps 1-4 based on the parameter inputs. 
###############################################

generate_estimate_discriminate <- function(params) {
  params %>% # Step 1: Parameterize the problem
      dgp_df_ovb() %>%  # Step 2: Define the data generation process
        estimator_fn() %>%  # Step 3: Estimate 
          disc_fn() %>% # Step 4: Pull out what you need
            data.frame(tau_hat = .) # store the result as a data frame object
}

# Try it out
params %>% generate_estimate_discriminate(.)


```

Our next step is to repeat this process lots of times via a Monte Carlo simulation. We'll keep the number of Monte Carlo runs small (1000) to speed up computation, but note that in practice we may need to do this thousands of times. 

```{r mc_ovb, exercise.setup = "omb1"}
#| echo: true
#| exercise: true
#| exercise.lines: 10


# Monte Carlo simulation based on 1000 different realizations of the DGP:
M = 1000
mc_result <- 1:M %>% map_df(~generate_estimate_discriminate(params))

# Take a peek at the output ...
mc_result %>%
  head() 

```

Now let's take a look at the sampling distribution of estimates. 


```{r mc_sd, exercise.setup = "mc_ovb"}
#| echo: true
#| exercise: true
#| exercise.lines: 10

plot_sampling_distribution(mc_result$tau_hat, truth = params$tau)
```

As we can see in the plot of the sampling distribution, our estimates are biased due to the omitted factor ($u_i$) that is correlated with treatment and the outcome. In our next session we will cover several estimation approaches to obtain an unbiased estimate of $\tau$. 

<!-- Last Line -->


