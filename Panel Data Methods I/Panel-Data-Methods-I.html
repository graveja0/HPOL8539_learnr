<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="true" />
<meta name="allow-skip" content="true" />
<meta name="learnr-version-prerender" content="0.10.5.9000" />

<title>Panel Data Methods 1: Fixed, Random and Correlated Random Effects</title>

<!-- header-includes START -->
<!-- HEAD_CONTENT -->
<!-- header-includes END -->
<!-- HEAD_CONTENT -->

<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>


<!-- taken from https://github.com/rstudio/rmarkdown/blob/de8a9c38618903627ca509f5401d50a0876079f7/inst/rmd/h/default.html#L293-L343 -->
<!-- tabsets -->
<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>
<!-- end tabsets -->


</head>

<body>
<a class='sr-only sr-only-focusable visually-hidden-focusable' href='#learnr-tutorial-content'>Skip to Tutorial Content</a>



<div class="pageContent band">
<main class="bandContent page">

<article class="topics" id="learnr-tutorial-content">

<div id="section-review-and-motivation-for-todays-session"
class="section level2">
<h2>Review and Motivation for Today’s Session</h2>
<p>Our objective today is to extend our consideration of a data
generation process (DGP) with unobserved heterogeneity.</p>
<p>Recall the basic DGP we introduced last week:</p>
<p><span class="math display">\[
Y_i = \mathbf{X}_i&#39;\beta + \tau D_i + \epsilon_i  \quad \quad \quad
Eq. 1
\]</span> where <span class="math inline">\(i\)</span> indexes
indiviudal units, <span class="math inline">\(\mathbf{X}_i\)</span> is a
vector of unit-level attributes, and <span
class="math inline">\(D_i\)</span> is a binary treatment indicator. Our
parameter of interest is <span class="math inline">\(\tau\)</span>.</p>
<p>Recall that with this DGP defined, we defined a full set of
parameters as the “ground” truth, and then simulated <span
class="math inline">\(M=1,000\)</span> separate datasets, each time
running a linear regression model. We extracted the <span
class="math inline">\(\hat \tau\)</span> estimate from each regression,
and then plotted their distribution.</p>
<p>Our basic process is shown below:</p>
<pre class="r"><code>params  # List of parameters governing the DGP.
generate_data_from_DGP = function(params) # Y_i = beta_0 + beta_1 X_i + tau D_i + epsilon_i 
estimate  = function(data) # lm(Y ~ X_i + D_i)
discriminate = function(estimates) # pull out tau_hat 
  
# Run the full four-step process once. 
define_parameters %&gt;%  # 1. Define the parameters and DGP.
  generate_data_from_DGP() %&gt;%  # 2. Generate data based on the DGP
    estimate() %&gt;%  # 3. Estimate based on the generated data
      discriminate()  # 4. Extract out  and  report what you need. 

# Now do it 1,000 times. 
do_it_all_at_once &lt;- function(params) {
  generate_data_from_DGP() %&gt;%  
      estimate() %&gt;% 
        discriminate() 
}
M = 1000
1:M %&gt;% map(~(do_it_all_at_once(params)))</code></pre>
<p>This differs from the usual research/evaluation process only in that
we control the “truth.” In practice, when we have an actual “real-life”
dataset, we would perform the following process:</p>
<pre class="r"><code>read_in_and_structure_data() %&gt;%  # 1. Read in our data
    estimate() %&gt;%  # 2. Estimate the model on the data
      discriminate()  # 3. Extract out and report what you need. </code></pre>
<p>Turning back to our exercises from last week, the parameter values
from our defined DGP, as well as the plotted sampling distribution, are
shown below.</p>
<table>
<caption>Parameter Values (Eq. 1)</caption>
<thead>
<tr class="header">
<th align="left">param</th>
<th align="right">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">N</td>
<td align="right">1000.0</td>
</tr>
<tr class="even">
<td align="left">mean_x_i</td>
<td align="right">2.0</td>
</tr>
<tr class="odd">
<td align="left">sd_x_i</td>
<td align="right">0.5</td>
</tr>
<tr class="even">
<td align="left">beta</td>
<td align="right">1.0</td>
</tr>
<tr class="odd">
<td align="left">tau</td>
<td align="right">0.5</td>
</tr>
<tr class="even">
<td align="left">sigma_sq_epsilon</td>
<td align="right">1.0</td>
</tr>
</tbody>
</table>
<div class="figure" style="text-align: center">
<img src="images/samp-dist-noUi.png" alt="Sampling Distribution of OLS Estimator of tau" width="50%" />
<p class="caption">
Sampling Distribution of OLS Estimator of tau
</p>
</div>
</div>
<div id="section-exercise-1-unobserved-heterogeneity"
class="section level2">
<h2>Exercise 1: Unobserved Heterogeneity</h2>
<p>Note that this exercise repeats Exercise 4 from last week’s
session.</p>
<p>We will next adapt the underlying DGP to include an unobserved
heterogeneity term <span class="math inline">\(U_i\)</span>:</p>
<p><span class="math display">\[
Y_i = \mathbf{X}_i&#39;\beta + \tau D_i + U_i +\epsilon_i \quad \quad
\quad Eq. 2
\]</span></p>
<div class="tutorial-exercise" data-label="ovb1" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="60">
<pre class="text"><code>##################################
# Step 1: Parameterize the Problem
##################################
params =list(
  N = 1000,
  mean_x_i = 2,
  sd_x_i = 0.5,
  beta = 1,
  tau = 0.5,
  sigma_sq_epsilon = 1
)

####################################################
# Step 2: Define a Data Generation Process Function
#####################################################
dgp_df_u =function(params) {
  with(params,{
    df =
      tibble(
        # Covariate
        x_i = rnorm(N, mean_x_i, sd_x_i),
        # ADD UNOBSERVED HETEROGENEITY TERM
        u_i = rnorm(N, mean = 0, sd = 1)) %&gt;% 
        # Induce correlation between u_i and treatment;
        # higher values of u_i make it more likely you&#39;re treated. 
        rowwise() %&gt;% # This allows us to get each value&#39;s pr_treated in the line below. 
        mutate(pr_treated = boot::inv.logit(u_i)) %&gt;% 
        ungroup() %&gt;%  # This undoes the rowwise 
        # Treatment indicator
        mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %&gt;% 
        mutate(epsilon_i = rnorm(N, mean = 0, sd = sigma_sq_epsilon)) %&gt;% 
        # u_i is also in the DGP for y_i 
        mutate(y_i = beta * x_i + tau * d_i + u_i + epsilon_i) %&gt;% 
        # because u_i is unobserved, we strip it from the &quot;observed&quot; data output. 
        select(-u_i)
    return(df)
  })
}

############################################
# 3. Define and Apply an Estimation Function
#############################################
estimator_fn = function(df) {
  out =
    df %&gt;% 
      lm(y_i ~ x_i + d_i, data = .)
  return(out)
}

########################################
# 4. Define the discriminator function 
# (For this exercise we want to extract tau-hat 
# i.e., the coefficient on treated)
########################################
disc_fn = function(fit) {
  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object
  out =fit_ %&gt;% 
    filter(term==&quot;d_i&quot;) %&gt;% 
    pull(estimate)
  
  return(out)
}

###############################################
# 5. Define a compound function that executes
# steps 1-4 based on the parameter inputs. 
###############################################

generate_estimate_discriminate &lt;- function(params) {
  params %&gt;% # Step 1: Parameterize the problem
      dgp_df_u() %&gt;%  # Step 2: Define the data generation process
        estimator_fn() %&gt;%  # Step 3: Estimate 
          disc_fn() %&gt;% # Step 4: Pull out what you need
            data.frame(tau_hat = .) # store the result as a data frame object
}</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Our next step is to repeat this process lots of times via a Monte
Carlo simulation. We’ll keep the number of Monte Carlo runs small (100)
to speed up computation, but note that in practice we may need to do
this thousands of times.</p>
<div class="tutorial-exercise" data-label="mc_ovb" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="7">
<pre class="text"><code># Monte Carlo simulation based on 100 different realizations of the DGP:
M = 100
result_lm &lt;- 1:M %&gt;% map_df(~generate_estimate_discriminate(params))

plot_sampling_distribution(result_lm$tau_hat, truth = params$tau)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>As we can see in the plot of the sampling distribution, our estimates
are biased due to the omitted factor (<span
class="math inline">\(u_i\)</span>) that is correlated with treatment
and the outcome.</p>
</div>
<div id="section-panel-data" class="section level2">
<h2>Panel Data</h2>
<p>As you read about for today, analyzing panel data opens up new ways
to estimate in such a way as to account for time-invariant unobserved
heterogeneity in the data generation process.</p>
<p>Our basic pivot is to move from a cross-sectional setting into a
panel setting. In terms of the data generation process, that often means
we will observe each unit (<span class="math inline">\(i\)</span>) in
our data at different points in time (<span
class="math inline">\(t\)</span>).<a href="#section-fn1"
class="footnote-ref" id="section-fnref1"><sup>1</sup></a></p>
<p>Let’s also suppose that when we move to the panel data setting, we
are at risk of an additional (time-related) dimension of unobserved
heterogeneity in our outcomes. This may be due to idiosyncratic
time-period “shocks” that are unrelated to the treatment.</p>
<p>Our DGP thus becomes:</p>
<p><span class="math display">\[
Y_{it} = \mathbf{X}_{it}&#39;\beta + \tau D_{it} + \color{red}{U} +
\epsilon_{it}
\]</span> By moving to a panel data setting, we collect
<em>repeated</em> observations on each unit <span
class="math inline">\(i\)</span> in our population. These repeated
observations are now indexed by <span
class="math inline">\(t\)</span>.</p>
<p>Also note that our unobserved heterogeneity term is now defined as
<span class="math inline">\(\color{red}{U = \delta_i +
\gamma_t}\)</span>, which captures both unit-specific heterogeneity
(<span class="math inline">\(\delta_i\)</span>) and time-specific
heterogeneity (<span class="math inline">\(\gamma_t\)</span>).</p>
<div
id="section-partitioning-the-dgp-into-systematic-and-stochastic-components"
class="section level3">
<h3>Partitioning the DGP Into Systematic and Stochastic Components</h3>
<p>Before we move on it is useful also to highlight two components of
our underlying DGP: a <strong>systematic</strong> component and a
<strong>stochastic</strong> component.<a href="#section-fn2"
class="footnote-ref" id="section-fnref2"><sup>2</sup></a> Under a DGP
without unobserved heterogeneity (we’ll add that in a bit), the
stochastic component is given by</p>
<p><span class="math display">\[
\begin{equation}
Y_{it} \sim f(\color{blue}{\theta},\color{orange}{\epsilon_{it}})
\end{equation}
\]</span></p>
<p>and the systematic component is given by:</p>
<p><span class="math display">\[
\color{blue}{\theta} = g(\color{blue}{\beta , \tau, X_{it},D_{it}})
\]</span></p>
<p>The above equations are generalized to accommodate any number of
outcome types (e.g., continuous, binary, categorical). Cast in terms of
a linear model, as we have specified above, we have</p>
<p><span class="math display">\[
Y_{it} \sim N(\color{blue}{\mu},\color{orange}{\sigma_{\epsilon}^2}),
\quad \mu = g(\color{blue}{\beta , \tau, X_{it},D_{it}}) =
\color{blue}{\mathbf{X_{it}}&#39;\beta + \tau D_{it} }
\]</span> Which we can also write as</p>
<p><span class="math display">\[
Y_i = \color{blue}{\mathbf{X_i}&#39;\beta + \tau D_i } +
\color{orange}{\epsilon_{it}}
\]</span> where <span
class="math inline">\(\color{orange}{\epsilon_{it}} \sim
N(0,\color{orange}{\sigma^2_{\epsilon}})\)</span>.</p>
<p>Note that in the above equations, the systematic component is
specified in <span
class="math inline">\(\color{blue}{\text{blue}}\)</span> and the
stochastic component in <span
class="math inline">\(\color{orange}{\text{orange}}\)</span>.</p>
<p>Intuitively, the systematic component tells us about the level of of
the outcome for individuals with the same value of <span
class="math inline">\(\mathbf{X_i}\)</span> and <span
class="math inline">\(D_i\)</span>; outcomes for these individuals will
be different, however, due to the stochastic (error term) component
governed by <span
class="math inline">\(\sigma_{\epsilon}^2\)</span>.</p>
<p>We’ll now turn back to the case with unobserved heterogeneity, which
is shown in <span
class="math inline">\(\color{red}{\text{red}}\)</span></p>
<p><span class="math display">\[
Y_{it} = \color{blue}{\mathbf{X}_{it}&#39;\beta} + \color{blue}{\tau
D_{it}} + \color{red}{U} + \color{orange}{\epsilon_{it}}
\]</span></p>
<p>As we will see below, how we deal with unobserved heterogeneity will
hinge on whether we absorb <span
class="math inline">\(\color{red}{U}\)</span> within the <span
class="math inline">\(\color{blue}{\text{systematic}}\)</span> or <span
class="math inline">\(\color{orange}{\text{stochastic}}\)</span>
component of the DGP.</p>
</div>
<div class="footnotes footnotes-end-of-section">
<hr />
<ol>
<li id="section-fn1"><p>Note, that for the following examples, <span
class="math inline">\(i\)</span> will represent individual units and
<span class="math inline">\(t\)</span> will represent a time dimension.
However, panel data could take any number of forms, such as students
(<span class="math inline">\(i\)</span>) within classrooms or schools
(<span class="math inline">\(t\)</span>), patients (<span
class="math inline">\(i\)</span>) treated at the same hospital (<span
class="math inline">\(t\)</span>). We can also think of panel data at
some higher level of aggregation than our unit of observation (e.g.,
individuals <span class="math inline">\(i\)</span> within states <span
class="math inline">\(g\)</span> over time <span
class="math inline">\(t\)</span>.)<a href="#section-fnref1"
class="footnote-back">↩︎</a></p></li>
<li id="section-fn2"><p>A nice source on this topic can be found <a
href="https://gking.harvard.edu/files/making.pdf">here</a><a
href="#section-fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
</div>
<div id="section-exercise-ii-panel-data" class="section level2">
<h2>Exercise II: Panel Data</h2>
<p>Let’s now augment our DGP to include this panel data component. We
will assume we observe individual units both pre- and post the treatment
time. Let’s assume for now that we observe each unit once before the
intervention time, and once after, so that the total number of time
periods is 2 (i.e., <span class="math inline">\(T=2\)</span>) and the
treatment time (<code>tx_time</code>) occurs at <span
class="math inline">\(t=2\)</span>.</p>
<div class="tutorial-exercise" data-label="dgp_panel_setup"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="45">
<pre class="text"><code>params_panel &lt;- list(
  N = 1000,
  T = 2,
  tx_time = 2, 
  rho_t = 0.8,
  beta_0 = 0.5,
  beta_1 = 2,
  tau = 0.5,
  p_d = 0.5
)

dgp_panel &lt;- function(params) {
  with(params, {

    # Time effects
    t_ &lt;-
      data.frame(t = 1:T,
                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %&gt;% as.vector())

    # Individual measures and effects
    i_ &lt;-
      data.frame(
        unit_id = 1:N,
        x_i = rnorm(N, mean = 0, sd = 1),
        u_i = rnorm(N, mean = 0, sd = 1)) %&gt;%
      rowwise() %&gt;% # This allows us to get each value&#39;s pr_treated in the line below. 
      mutate(pr_treated = boot::inv.logit(u_i)) %&gt;% 
      ungroup() %&gt;%  # This undoes the rowwise 
      # Treatment indicator
      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %&gt;% 
      ungroup()

    crossing(unit_id = i_$unit_id,t = t_$t) %&gt;%
      left_join(i_,&quot;unit_id&quot;) %&gt;%
      left_join(t_,&quot;t&quot;) %&gt;%
      mutate(d_i = ifelse(t&lt;tx_time,0,d_i)) %&gt;%
      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))
  })
}

params_panel %&gt;% 
  dgp_panel()</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Consistent with the DGP, notice in the output that each individual
unit is observed twice.</p>
</div>
<div id="section-exercise-3-pooled-ols" class="section level2">
<h2>Exercise 3: Pooled OLS</h2>
<p>We will first consider the case where we simply fit an ordinary least
squares (OLS) regression to our (simulated) panel data. Essentially, we
allow the unobserved heterogeneity terms to stay in the error term:</p>
<p><span class="math display">\[
\begin{aligned}
Y_{it} &amp;=\color{blue}{\mathbf{X}_{it}&#39;\beta + \tau D_{it}} +
\color{orange}{U} + \color{orange}{\epsilon_{it}} \\
Y_{it} &amp;=\color{blue}{\mathbf{X}_{it}&#39;\beta + \tau D_{it}} +
\overbrace{\color{orange}{\delta_i} + \color{orange}{\gamma_t} +
\color{orange}{\epsilon_{it}}}^{\color{orange}{\eta_{it}}} \\
&amp;= \color{blue}{\mathbf{X}_{it}&#39;\beta + \tau D_{it}}  +
\color{orange}{\eta_{it}} \quad \quad \quad Eq. 3
\end{aligned}
\]</span> Thus, our estimation function is:</p>
<div class="tutorial-exercise" data-label="pooledOLS1"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="9">
<pre class="text"><code>estimator_fn_pols &lt;- function(df) {
  lm(y_i ~ x_i + d_i, data = df)
}

params_panel %&gt;% 
  dgp_panel() %&gt;% 
    estimator_fn_pols()</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Recall that in the DGP defined above, we have induced correlation
between unobserved (unit-level) heterogeneity and the treatment
indicator (<span class="math inline">\(D_i\)</span>). We did so by
setting the probability of treatment for each individual as a function
(inverse logit) of <span class="math inline">\(U_i\)</span>, (i.e.,
<code>pr_treated = inv.logit(u_i)</code>).</p>
<p>In addition, unit- and time-level heterogeneity also enters the
formula for our outcome <span class="math inline">\(Y_i\)</span>,</p>
<p><span class="math display">\[
Y_{it} = \color{blue}{\mathbf{X}_{it}&#39;\beta} + \color{blue}{\tau
D_{it}} + \color{orange}{\delta_i} + \color{orange}{\gamma_t} +
\color{orange}{\epsilon_{it}}
\]</span></p>
<p>Therefore, if we simulate and construct a sampling distribution for
the POLS estimator for <span class="math inline">\(\tau\)</span>, we
will obtain inconsistent estimates:</p>
<div class="tutorial-exercise" data-label="pooledOLS2"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="22">
<pre class="text"><code># Define a discrimination function for the POLS estimator 
disc_fn_pols = function(fit) {
  fit_ =broom::tidy(fit)   
  out =fit_ %&gt;% 
    filter(term==&quot;d_i&quot;) %&gt;% 
    pull(estimate)
  return(out)
}

generate_estimate_discriminate_pols &lt;- function(params) {
  params %&gt;% # Step 1: Parameterize the problem
      dgp_panel() %&gt;%  # Step 2: DGP
        estimator_fn_pols() %&gt;%  # Step 3: Estimate 
          disc_fn_pols() %&gt;% # Step 4: Coefficient of interest
            data.frame(tau_hat = .) # Store as data fram
}

M = 100
result_pols &lt;- 1:M %&gt;% map_df(~generate_estimate_discriminate_pols(params_panel))
plot_sampling_distribution(result_pols$tau_hat, truth = params_panel$tau)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<div id="section-aside-a-note-on-inference" class="section level3">
<h3>Aside: A Note on Inference</h3>
<p>Another issue we will run across with pooled OLS and panel data is
known as “pseudo-replication.” This is the idea that, with panel data,
there is often correlation in <span class="math inline">\(Y_i\)</span>
within units and across time. Depending on the degree of correlation, we
don’t want to act is if we have <span class="math inline">\(N*T\)</span>
rows of independent data; we may have an <em>effective</em> sample size
closer to <span class="math inline">\(N\)</span>.<a href="#section-fn3"
class="footnote-ref" id="section-fnref3"><sup>3</sup></a> Therefore, we
have to adjust our standard errors to account for the repeated measures
in our data.</p>
<p>More generally, we will continue to focus on parameter estimation for
now, and cover issues related to statistical inference in a
not-to-distant case study.</p>
</div>
<div class="footnotes footnotes-end-of-section">
<hr />
<ol start="3">
<li id="section-fn3"><p>These types of considerations are a key
motivation for the use of random effects and hierarchical modeling more
generally—you can take entire courses on this, so I will only tease it
here.<a href="#section-fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
</div>
<div id="section-exercise-4-random-effects" class="section level2">
<h2>Exercise 4: Random Effects</h2>
<p>In a random effects model, we assume that the unit- and time-specific
effects (i.e., <span class="math inline">\(\delta_i\)</span> and <span
class="math inline">\(\gamma_i\)</span>, respectively) are random
variables drawn from a distribution.<a href="#section-fn4"
class="footnote-ref" id="section-fnref4"><sup>4</sup></a></p>
<p>We keep these unobserved heterogeneity terms in the stochastic
component of the model, and assume they are independent of <span
class="math inline">\(\epsilon_i\)</span>, and are thus uncorrelated
with the systematic components (i.e., <span
class="math inline">\(X_i\)</span> and <span
class="math inline">\(D_i\)</span>) in the DGP.</p>
<p>These random effects have mean zero and standard deviation as
follows:</p>
<p><span class="math display">\[
\begin{aligned}
\delta_i &amp;\sim N(0,\sigma^2_i) \\
\gamma_t &amp;\sim N(0,\sigma^2_t)
\end{aligned}
\]</span> Note that we have now introduced two new parameters to our
model: <span class="math inline">\(\sigma^2_i\)</span> and <span
class="math inline">\(\sigma^2_t\)</span>; these are parameters that
will be estimated along with <span
class="math inline">\(\mathbf{\beta}\)</span> and <span
class="math inline">\(\tau\)</span> in our regression.<a
href="#section-fn5" class="footnote-ref"
id="section-fnref5"><sup>5</sup></a></p>
<p>In summary, and expressed in terms of our orignial DGP, we have,</p>
<p><span class="math display">\[
\begin{aligned}
Y_{it} &amp;= \color{blue}{\mathbf{X}_{it}&#39;\beta + \tau D_{it}} +
\overbrace{\color{orange}{U}  +
\color{orange}{\epsilon_{it}}}^{\color{orange}{v_{it}}} \\
&amp;= \color{blue}{\mathbf{X}_{it}&#39;\beta + \tau D_{it}} +
\color{orange}{v_{it}} \quad \quad \quad Eq. 4 \\
\color{orange}{v_{it}} &amp;= \color{orange}{U} +
\color{orange}{\epsilon_{it}} \\
&amp;= \color{orange}{\delta_i} +
\color{orange}{\gamma_t}  +\color{orange}{\epsilon_{it}} \\
\delta_i &amp;\sim N(0,\sigma^2_i) \\
\gamma_t &amp;\sim N(0,\sigma^2_t)
\end{aligned}
\]</span></p>
<div id="section-random-effects-r-code" class="section level3">
<h3>Random Effects: R Code</h3>
<p>In R, a random effects model can be estimated using many packages. In
the estimator function below, I will draw on the <code>lmer4</code>
package.</p>
<div class="tutorial-exercise" data-label="re1" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="11">
<pre class="text"><code>estimator_fn_re &lt;- function(df) {
   lmer(y_i ~ x_i+ d_i + (1|unit_id) + (1|t), df)
}

params_panel %&gt;% 
  dgp_panel() %&gt;% 
    estimator_fn_re()</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div class="footnotes footnotes-end-of-section">
<hr />
<ol start="4">
<li id="section-fn4"><p>Usually a normal distribution.<a
href="#section-fnref4" class="footnote-back">↩︎</a></p></li>
<li id="section-fn5"><p>A nice resource on random effects models can be
found <a
href="https://link.springer.com/article/10.1007/s11135-014-0060-5">here</a>
and <a
href="https://www.cambridge.org/core/journals/political-science-research-and-methods/article/explaining-fixed-effects-random-effects-modeling-of-timeseries-crosssectional-and-panel-data/0334A27557D15848549120FE8ECD8D63">here</a><a
href="#section-fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<div id="section-aside-fixed-and-random-effects" class="section level3">
<h3>Aside: “Fixed” and “Random” Effects</h3>
<p>Notice in the output that there is a section called <strong>Random
effects</strong> and a section called <strong>Fixed effects</strong>.
The random effects results refer to the parameter estimates for the
<em>stochastic</em> component of the model. That is, the
<code>Std.Dev.</code> estimates under the Random effects section results
refer to the regression estimates of <span
class="math inline">\(\sigma^2_i\)</span>, <span
class="math inline">\(\sigma^2_t\)</span> and <span
class="math inline">\(\sigma^2_{\epsilon}\)</span>, respectively.</p>
<p>However, <strong>the section titled “Fixed effects” does <em>NOT</em>
provide estimates from a fixed effects regression.</strong> This
alternative use of the term “fixed effects” highlights an important
difference in statistical terminology across fields. These estimates
refer to a “fixed effect” as a statistician would call them, not as an
econometrician would call them.</p>
<p>I will briefly cover what a statistician often means when they use
the term “fixed effects” below, and leave the econometric definition
until later in this document.</p>
<p><img src="images/spiderman.jpeg" /></p>
<div id="section-fixed-effects-the-traditional-statistics-definition"
class="section level4">
<h4>Fixed Effects: The Traditional Statistics Definition</h4>
<p>Suppose we were interested in evaluating the effect of a new dietary
intervention administered through physicians offices. Let’s index
individual patients by <span class="math inline">\(i\)</span> and
physicians by <span class="math inline">\(k\)</span>. Assume, also, that
we collect panel data on patients within physician offices where we
follow patients over time (<span class="math inline">\(t\)</span>).</p>
<p>Our ultimate goal is to assess whether a change in some factor (<span
class="math inline">\(D_{it}\)</span>, the dietary change) affects the
primary outcome <span class="math inline">\(Y_{it}\)</span>. For our
purposes here it does not matter whether <span
class="math inline">\(D_{it}\)</span> is a continuous measure (e.g.,
number of calories) or a binary intervention (e.g., being assigned to a
dietary coach).</p>
<p>In this example, units in our data have attributes that we care about
for the evaluation. For example, we have an inherent interest in the
effect of treatment <span class="math inline">\(D_{it}\)</span>, which
varies among individuals. Since our primary interest is “fixed” on the
effect of diet on outcomes, a statistician would call the effect
estimate of <span class="math inline">\(\hat \tau\)</span> a “fixed
effect” in the regression.</p>
<p>There are other relevant attributes and sources of heterogeneity at
play as well, however—and accounting for them is often important not
only from a bias/consistency perspective, but also from a statistical
inference perspective.</p>
<p>For example, physicians in our sample likely differ in their level of
(dietary habit) engagement with their patients. This may also matter for
patient outcomes, and also possibly for whether or not a patient
receives the intervention—so accounting for this source of
physician-level heterogeneity may be important for all of the reasons
why we are so focused on unobserved heterogeneity (<span
class="math inline">\(U\)</span>) across different units in our
data.</p>
<p>Physician-level attributes also matter because they are shared among
patients who see the same doctor. That is, patients who share the same
physician are likely exposed to similar if not identical levels of
dietary engagement–so there may be correlation in our outcomes among
patients in the same physician clinic. This raises the issue of
“pseudo-replication” covered above, since not every observation in our
data can be considered a new, “fresh” draw of independent
information.</p>
<p>A critical point, however, is that for our evaluation <em>we are not
inherently interested in the effect of one physician vs. another on
outcomes.</em> Thus, if the assumptions of random effects hold, we can
safely relegate our accounting for this heterogeneity to the stochastic
component of the model. By including these attributes as random effects,
we take care of any issues related to unobserved heterogeneity
<em>and</em> statistical issues that come up with possible
pseudo-replication in our sample.</p>
</div>
</div>
<div id="section-random-effects-sampling-distribution-for-example"
class="section level3">
<h3>Random Effects: Sampling Distribution for Example</h3>
<p>With all that out of the way, let’s repeat our data generation and
estimation process 100 times and look at the sampling distribution of
<span class="math inline">\(\hat \tau\)</span> estimates:</p>
<div class="tutorial-exercise" data-label="re2" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="31">
<pre class="text"><code># Define a discriminator function
disc_fn_re &lt;- function(fit) {
  fit %&gt;% summary() %&gt;% pluck(&quot;coefficients&quot;) %&gt;%
    data.frame() %&gt;%
    rownames_to_column() %&gt;%
    janitor::clean_names() %&gt;%
    filter(rowname==&quot;d_i&quot;) %&gt;%
    pull(estimate) %&gt;%
    as.vector()
}

# Bundle it all together in one function. 
generate_estimate_discriminate_re &lt;- function(params) {
  suppressWarnings({
    suppressMessages({
      params %&gt;% # Step 1: Parameterize the problem
        dgp_panel() %&gt;%  # Step 2: Define the data generation process
          estimator_fn_re() %&gt;%  # Step 3: Estimate 
            disc_fn_re() %&gt;% # Step 4: Pull out what you need
              data.frame(tau_hat = .) # store the result as a data frame object
    })
  })
}

# Run it 100 times!
M = 100
result_re &lt;- 1:M %&gt;% map_df(~generate_estimate_discriminate_re(params_panel))

plot_sampling_distribution(result_re$tau_hat, truth = params_panel$tau)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>As you can see in the sampling distribution, we end up with a
distribution of estimates far from the truth.</p>
<p>Why is this? Recall, again, that a random effects model places
assumptions on correlations between the random effects and the included
regressors (i.e., <span class="math inline">\(X_{it}\)</span> and <span
class="math inline">\(D_{it}\)</span>). We specifically <em>assume</em>
that the random effects <strong>are not correlated</strong> with either
<span class="math inline">\(X_{it}\)</span> or <span
class="math inline">\(D_{it}\)</span>.</p>
<p>But in our data generation function, we define the probability of
treatment as a function of <span class="math inline">\(u_i\)</span>.
Specifically, it is defined as
<code>pr_treated = inv_logit(delta_i)</code>. In addition to determining
the probability of treatment, the unobserved heterogeneity terms also
enter the DGP for the outcome <span
class="math inline">\(Y_{it}\)</span>:</p>
<p><span class="math display">\[
Y_{it} = \mathbf{X}_{it}&#39;\beta + \tau D_{it} + \delta_i + \gamma_t +
\epsilon_{it}
\]</span></p>
<p>We therefore have a situation in our DGP where the random effects,
while <em>assumed</em> to be uncorrelated with the regressors
(esp. <span class="math inline">\(D_i\)</span>), actually are correlated
with them. <strong>So the assumptions of random effects regression are
not met for the specified DGP in this example.</strong></p>
<p>All is not lost for random effects, however. We’ll come back to
random effects estimation later to recover ourselves when we fit a
<strong>correlated random effects regression.</strong> But we’ll first
turn our attention to <strong>fixed effects</strong> regression from an
econometric perspective.</p>
</div>
</div>
<div id="section-exercise-5-dummy-variable-regression"
class="section level2">
<h2>Exercise 5: Dummy Variable Regression</h2>
<p>Our first foray into fixed effect regression will consider dummy
variable regression. The idea here is simple: rather than assume the
unobserved heterogeneity terms can sit comfortably in the error term,
we’ll simply estimate a separate intercept for every unit and time
period in our data:</p>
<p><span class="math display">\[
\begin{aligned}
Y_{it} &amp;= \underbrace{\color{blue}{\mathbf{X}_{it}&#39;\beta} +
\color{blue}{\tau D_i} + \color{blue}{\mathbf{\delta}_i} +
\color{blue}{\mathbf{\gamma}_t}}_{\text{systematic component}}   +
\color{orange}{\epsilon_{it}}
\end{aligned}
\]</span></p>
<p>Note how this differs from the random effects model in that we have
pulled the unobserved heterogeneity terms into the systematic component,
whereas under the random effects approach we assumed these terms could
remain in the stochastic component:</p>
<p><span class="math display">\[
\begin{aligned}
Y_{it} &amp;= \color{blue}{\mathbf{X}_{it}&#39;\beta} +
\color{blue}{\tau D_i} + \underbrace{\color{orange}{\mathbf{\delta}_i} +
\color{orange}{\mathbf{\gamma}_t}  +
\color{orange}{\epsilon_{it}}}_{\text{stochastic component}}
\end{aligned}
\]</span> What is important about this change? First, by including the
unobserved heterogeneity terms directly in the regression, our estimates
of other parameters are conditioned on them; we thus control for any
arbitrary correlation between the unobserved heterogeneity terms and the
other regressors in our model. This is a big advantage of fixed effect
approches over random effect approaches.<a href="#section-fn6"
class="footnote-ref" id="section-fnref6"><sup>6</sup></a></p>
</div>
<div class="footnotes footnotes-end-of-section">
<hr />
<ol start="6">
<li id="section-fn6"><p>Though, again, correlated random effects will
address this issue too, as we’ll see shortly.<a href="#section-fnref6"
class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<div id="section-dummy-variable-regression-r-code"
class="section level2">
<h2>Dummy Variable Regression: R Code</h2>
<p>Let’s go ahead and define an estimation function for dummy variable
regression. In the code below, we simply include the
<code>unit_id</code> and time (<code>t</code>) variables as factors in
the regression model. When the regression runs, this amounts to creating
a dummy variable for each unit in our data, and a dummy variable for
each time period. <strong>These unit- and time-specific effects are the
econometric “fixed effects” in our regression.</strong></p>
<p>Go ahead an run a dummy variable fixed effect regression and take a
look at the output.</p>
<div class="tutorial-exercise" data-label="dummy1" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="15">
<pre class="text"><code>estimator_fn_dummy &lt;- function(df) {
  lm(y_i ~ d_i + factor(t) + factor(unit_id), df)
}

fit_dummy &lt;- 
  params_panel %&gt;% 
    dgp_panel() %&gt;% 
      estimator_fn_dummy()

fit_dummy %&gt;% 
  broom::tidy() </code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-dummy-variable-regression-estimates"
class="section level2">
<h2>Dummy Variable Regression: Estimates</h2>
<p>Notice in the regression output that there is a coefficient estimated
for <em>each and every</em> unit and <em>each and every</em> time period
in our data. That’s a lot of coefficients! For this reason, the model
also took fairly long to run. So long, in fact, that we won’t even
consider a “live” version of the simulation exercise (i.e., DGP +
estimation 1,000 times over) because it would take ~45min for the full
set of results to compile. The code to do so is provided below,
however.</p>
<pre class="r"><code>generate_estimate_discriminate_dummy &lt;- function(params) {
  params %&gt;% # Step 1: Parameterize the problem
      dgp_panel() %&gt;%  # Step 2: Define the data generation process
        estimator_fn_dummy() %&gt;%  # Step 3: Estimate 
          disc_fn() %&gt;% # Step 4: Pull out what you need
            data.frame(tau_hat = .) # store the result as a data frame object
}

M = 1000
result_dummy &lt;- 
  1:M %&gt;% 
  map_multicore(~generate_estimate_discriminate_dummy(params_panel)) %&gt;% 
  bind_rows()

plot_sampling_distribution(result_dummy$tau_hat, truth = params$tau)</code></pre>
<p>Prior to class I did run the entire 1,000 run simulation, and
constructed the sampling distribution of estimates. Let’s take a look at
that now:</p>
<p><img src="images/samp-dist-dummy.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Lo and behold, our dummy variable “fixed effect” regression has
recovered the truth!</p>
<p>So what happened here? Essentially, by fitting a separate intercept
for every unit and time period in our data, we “control for” any fixed
attributes. Thus, because our unobserved heterogeneity was fixed (by
unit and time, respectively) we have controlled for them in our
analysis.</p>
<p>It is generally not adviseable to fit dummy variable fixed effect
regression when the number of effects you need to fit is large. So we’ll
next turn our attention to several alternative fixed effect approaches
to account for unobserved heterogeneity in our evaluation.</p>
</div>
<div id="section-exercise-6-first-differences" class="section level2">
<h2>Exercise 6: First-Differences</h2>
<p>To make exposition of the first differences estimator easier let’s
simplify our underlying DGP and simply remove the term that captures
unobserved time-level heterogeneity (i.e., remove <span
class="math inline">\(\gamma_t\)</span> from the DGP):</p>
<p><span class="math display">\[
Y_{it} = \mathbf{X}_{it}&#39;\beta + \tau D_{it} + \delta_i  +
\epsilon_{it} \quad \quad \quad Eq.\text{ }  DGP_t
\]</span> Now let’s think about <span
class="math inline">\(Y_{it}\)</span> at the adjacent, preceding point
in time: <span class="math inline">\(t-1\)</span>.</p>
<p><span class="math display">\[
Y_{i,t-1} =  \mathbf{X}_{i,t-1}&#39;\beta + \tau D_{i,t-1} + \delta_i +
\epsilon_{it} + \epsilon_{i,t-1} \quad \quad \quad Eq. \text{ }
DGP_{t-1}
\]</span> Now let’s take the difference between Eq. <span
class="math inline">\(DGP_t\)</span> and Eq. <span
class="math inline">\(DGP_{t-1}\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
Y_{it} - Y_{i,t-1} &amp;= (\mathbf{X}_{it} -
\mathbf{X}_{i,t-1})&#39;\beta + \tau (D_{it} - D_{i,t-1}) + (\delta_i -
\delta_i) +  (\epsilon_{it} - \epsilon_{i,t-1}) \\
&amp;= (\mathbf{X}_{it} - \mathbf{X}_{i,t-1})&#39;\beta + \tau (D_{it} -
D_{i,t-1}) + (\epsilon_{it} - \epsilon_{i,t-1}) \quad \quad \quad Eq. 5
\end{aligned}
\]</span> What do we <strong>not</strong> see in Eq. 5? Our unobserved
heterogeneity term <span class="math inline">\(\delta_i\)</span>! Why?
Because heterogeneity remains <em>fixed</em> across times, when we take
the difference across time periods it drops out of the equation.<a
href="#section-fn7" class="footnote-ref"
id="section-fnref7"><sup>7</sup></a></p>
</div>
<div class="footnotes footnotes-end-of-section">
<hr />
<ol start="7">
<li id="section-fn7"><p>Note that any other unit-specific measure we
have in our data would drop out for the same reasons, too.<a
href="#section-fnref7" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<div id="section-first-differences-r-code" class="section level2">
<h2>First Differences: R Code</h2>
<p>To estimate a first-differences regression we need to add another
step: for each measure in our regression, we take the difference between
adjacent time periods.</p>
<div class="tutorial-exercise" data-label="fistdiff1"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="23">
<pre class="text"><code>construct_first_diff &lt;- function(df) {
  df_ &lt;- 
    df %&gt;% 
      arrange(unit_id,t) %&gt;% 
      group_by(unit_id) %&gt;% 
      mutate(y_fd = y_i - lag(y_i),
             x_fd = x_i - lag(x_i),
             d_fd = d_i - lag(d_i)) %&gt;% 
      filter(t==2)
  return(df_)
}

estimate_first_diff &lt;- function(df) {
  lm(y_fd ~ d_fd , data = df)
}

params_panel %&gt;% 
  dgp_panel() %&gt;% 
    construct_first_diff() %&gt;% 
      estimate_first_diff() %&gt;% 
        summary() </code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Now let’s repeat the process and take a look at the sampling
distribution:</p>
<div class="tutorial-exercise" data-label="fistdiff2"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="30">
<pre class="text"><code>disc_fn_first_diff = function(fit) {
  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object
  out =fit_ %&gt;% 
    filter(term==&quot;d_fd&quot;) %&gt;% 
    pull(estimate)
  
  return(out)
}

generate_estimate_discriminate_first_diff &lt;- function(params) {
  params_panel %&gt;% 
    dgp_panel() %&gt;% 
      construct_first_diff() %&gt;% 
        estimate_first_diff() %&gt;% 
          disc_fn_first_diff() %&gt;% 
              data.frame(tau_hat = .) # store the result as a data frame object
}

 
M = 100
result_first_diff &lt;- 
  1:M %&gt;% 
  map_df(~generate_estimate_discriminate_first_diff(params_panel)) 

plot_sampling_distribution(result_first_diff$tau_hat, truth = params_panel$tau)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div
id="section-first-differnences-within-vs.-between-variation-and-other-takeaways"
class="section level2">
<h2>First Differnences: Within vs. Between Variation and Other
Takeaways</h2>
<p>An important takeaway from a first-differences approach is that we
net out all unit-level heterogeneity (<span
class="math inline">\(\delta_i\)</span>). This heterogeneity is “fixed”
within individuals (i.e., it remains fixed over time), but varies
<em>across</em> individuals.</p>
<p>By only comparing units to themselves (over time), the first
differences estimator focuses estimation <em>exclusivily</em> on
variation that occurs <em>within</em> units; by transoforming the data,
we literally threw out all the variation in our data that occurs
<em>across</em> units but which, <em>within</em> those units, does not
vary over time. Because these attributes are “fixed” across other
dimensions of our panel (i.e., time) this is how we can appreciate the
use of the term “fixed effects” as it is widely taught in
econometrics.</p>
<p>This notion of “within” vs. “between” variation is very important for
understanding fixed and random effects regression approaches to
estimation using panel data. In short, fixed effect estimators make
exclusive use within variation, whereas (<a
href="https://graveja0.github.io/HPOL8539-F2022/blog/posts/quasi-demeaning.html">as
is covered in a blog post on the topic</a>) the random effects approach
draws on <em>both</em> within and between variation. The degree to which
random effects draws on within vs. between variation depends on the
underlying data correlation patterns, however.</p>
<p>The bottom line is that when you hear “fixed effect” from a social
science perspective, what we are talking about is a regression approach
that leverages <em>only</em> within variation. Because we are ignoring
an entire dimension of variability in our data (i.e., variation across
units), we aren’t using as much of the information in our data to
estimate parameters–and for this reason, fixed effect approaches are
less “efficient” (i.e., the sampling distributions are thicker) than
random effect approaches.</p>
</div>
<div id="section-exercise-7-demeaning" class="section level2">
<h2>Exercise 7: Demeaning</h2>
<p>A more generalized approach to fixed effects uses a technique called
“de-meaning.” The idea is simple: for each cross-sectional unit in our
data (i.e., <code>unit_id</code>) we obtain the mean (averaged across
time periods) for the outcome and any regressors in our model. We then
subtract this mean from each individual.</p>
<p><span class="math display">\[
\begin{align}
(Y_{it}-\bar{Y_i}) &amp;= (\mathbf{X}_{it}-\bar{\mathbf{X}_i})&#39;\beta
+ \tau (D_{it}-\bar{D_i}) + (U_i - \bar{U_i)} + (\epsilon_{it} -
\bar{\epsilon_i}) \\
&amp;= (\mathbf{X}_{it}-\bar{\mathbf{X}_i})&#39;\beta + \tau
(D_{it}-\bar{D_i})  + (\epsilon_{it} - \bar{\epsilon_i}) \quad \quad
\quad Eq. 6
\end{align}
\]</span></p>
<p>Again, because our unobserved heterogeneity term is fixed across
time, the “mean” of <span class="math inline">\(\delta_i\)</span> is
<span class="math inline">\(\delta_i\)</span>. Therefore, when we demean
our data, <span class="math inline">\(\delta_i\)</span> drops out of the
equation! By the same token, we also lose any time-invariant attributes
of the underlying units, i.e., <span
class="math inline">\(X_i\)</span>.</p>
<div id="section-demeaning-with-time-and-unit-fixed-effects"
class="section level3">
<h3>Demeaning with Time and Unit Fixed Effects</h3>
<p>In our DGP and running example, we have two dimensions to account
for: units and time. To accomodate multiple fixed effect dimensions, the
demeaning process is very similar – the only difference is that we have
to add back in the “grand mean” to each variable.</p>
<p><span class="math display">\[
\begin{align}
(Y_{it}-\bar{Y_i} - \bar{Y_t} + \bar Y)
&amp;=  (\mathbf{X}_{it}-\bar{\mathbf{X}_i} - \bar{\mathbf{X}_t} +
\bar{\mathbf{X}})&#39;\beta + \tau (D_{it}-\bar{D_i} - \bar{D_t} +
\bar{D})  + (\epsilon_{it} - \bar{\epsilon_i} - \bar{\epsilon_t} +
\bar{\epsilon}) \quad \quad \quad Eq. 7
\end{align}
\]</span> Where <span class="math inline">\(\bar{Y_i}\)</span> is the
unit-level mean of <span class="math inline">\(Y\)</span>, <span
class="math inline">\(\bar{Y_t}\)</span> is the mean of <span
class="math inline">\(Y\)</span> in time period <span
class="math inline">\(t\)</span>, and <span class="math inline">\(\bar
Y\)</span> is the overall mean of <span class="math inline">\(Y\)</span>
in our data. Similar definitions apply for <span
class="math inline">\(\mathbf{X_i}\)</span> and <span
class="math inline">\(D_i\)</span>.<a href="#section-fn8"
class="footnote-ref" id="section-fnref8"><sup>8</sup></a></p>
<p>Because this so-called “two-way” fixed effects approach is so common
in the literature, we will construct our example using Eq. 7 as applied
to our simulated data.</p>
<div class="tutorial-exercise" data-label="demean1" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="25">
<pre class="text"><code>demean_data &lt;- function(df) {
  df_ &lt;- 
    df %&gt;% 
      mutate(
            # Step 1: Add in the global mean.
            y_dm = y_i + mean(y_i),
            d_dm = d_i + mean(d_i)) %&gt;% 
            # Step 2: Subtract out the time-period means
            group_by(t) %&gt;% 
            mutate(y_dm = y_dm - mean(y_dm),
            d_dm = d_dm - mean(d_i)) %&gt;% 
            # Step 3: Subtract out the unit-level means. 
            group_by(unit_id) %&gt;% 
            mutate(y_dm = y_dm - mean(y_dm),
            d_dm = d_dm - mean(d_dm)) %&gt;% 
            ungroup()

  return(df_)
}

params_panel %&gt;% 
  dgp_panel() %&gt;% 
    demean_data() </code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
We then define an estimation function based on a linear regression (lm):
<div class="tutorial-exercise" data-label="demean2" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="10">
<pre class="text"><code>estimator_fn_dm &lt;- function(df) {
  lm(y_dm ~ d_dm   , data = df)
}

set.seed(123)
params_panel %&gt;% 
  dgp_panel() %&gt;% 
    demean_data() %&gt;% 
      estimator_fn_dm()</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>There are “canned” fixed effect regression commands in R (and Stata)
that do all of this for you in the background. That is, you don’t even
need to de-mean your data!</p>
<div class="tutorial-exercise" data-label="demean3" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="11">
<pre class="text"><code>estimator_fn_dm2 &lt;- function(df) {
  feglm(y_i ~  d_i | t + unit_id, df, family = &quot;gaussian&quot;)
}

set.seed(123)
params_panel %&gt;% 
  dgp_panel() %&gt;% 
    demean_data() %&gt;% 
      estimator_fn_dm2()</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Notice two things in the output:</p>
<ol style="list-style-type: decimal">
<li>The coefficient estimates for <span class="math inline">\(\hat
\tau\)</span> are the identical whether we manually demean and fit a
linear regression, or simply fit a fixed effect regression command.</li>
<li>There are only two coefficient parameters estimated: the intercept
and <span class="math inline">\(\hat \tau\)</span>. By demeaning we have
sidestepped the need to define a separate indicator for each unit and
time. This speeds up estimation <em>considerably</em>.</li>
</ol>
<p>Now let’s simulate and plot a sampling distribution:</p>
<div class="tutorial-exercise" data-label="demean4" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="28">
<pre class="text"><code># Define a discriminator function that collects estimates of \hat \tau
disc_fn_dm = function(fit) {
  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object
  out =fit_ %&gt;% 
    filter(term==&quot;d_dm&quot;) %&gt;% 
    pull(estimate)
  
  return(out)
}

# Bundle it all together in a single function. 
generate_estimate_discriminate_dm &lt;- function(params) {
  params %&gt;% 
    dgp_panel() %&gt;% 
        demean_data() %&gt;% 
            estimator_fn_dm() %&gt;% 
              disc_fn_dm() %&gt;% 
                data.frame(tau_hat = .) # store the result as a data frame object
}

M = 100
result_dm &lt;- 
  1:M %&gt;% 
  map_df(~generate_estimate_discriminate_dm(params_panel)) 

plot_sampling_distribution(result_dm$tau_hat, truth = params_panel$tau)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div class="footnotes footnotes-end-of-section">
<hr />
<ol start="8">
<li id="section-fn8"><p>You can find a nice discussion of the underlying
math <a
href="https://stats.stackexchange.com/questions/246548/difference-between-one-way-and-two-way-fixed-effects-and-their-estimation">here</a><a
href="#section-fnref8" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
</div>
<div
id="section-quasi-demeaning-the-link-between-pooled-ols-fixed-and-random-effects"
class="section level2">
<h2>Quasi-Demeaning – The Link Between Pooled OLS, Fixed and Random
Effects</h2>
<p>It turns out that random effects sits in-between pooled OLS and fixed
effects. Without going into the gory detailes, the random effects model
can be represented as a “quasi-demeaned” model:</p>
<p><span class="math display">\[
\begin{align}
(Y_{it}-\theta \bar{Y_i}) = (\mathbf{X}_{it}-\theta
\bar{\mathbf{X}_i})&#39;\beta + \tau (D_{it}-\theta \bar{D_i})  +
(\epsilon_{it} - \theta \bar{\epsilon_i}) \quad \quad \quad Eq. 8
\end{align}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\theta = 1 - \bigg [\frac{\sigma^2_\epsilon}{(\sigma^2_\epsilon +
T\sigma^2_u)}\bigg ]^{1/2}
\]</span></p>
<p>In the above, <span class="math inline">\(\sigma_u\)</span> is the
variance of unit-level heterogeneity, and <span
class="math inline">\(\sigma_{\epsilon}\)</span> is the variance of
<span class="math inline">\(\epsilon_{it}\)</span>. And recall <span
class="math inline">\(T\)</span> is the total number of repeated
unit-level observations in our panel (e.g., the total number of time
periods, etc.)</p>
<p>What can we take away from this?</p>
<ol style="list-style-type: decimal">
<li>When <span class="math inline">\(\theta = 0\)</span>, Eq. 8 reduces
pooled regression. When is this the case?</li>
</ol>
<ul>
<li>If the term <span class="math inline">\(T\sigma^2_u\)</span> is 0,
i.e., <span class="math inline">\(\sigma^2_u=0\)</span> or there is no
variation in individual heterogeneity.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>When <span class="math inline">\(\theta = 1\)</span>, it is
equivalent to fixed effects regression based on full de-meaning. When is
this the case?</li>
</ol>
<ul>
<li>If the term <span class="math inline">\(T\sigma^2_u\)</span> gets
super large (more formally, it would need to blast off towards
infinity…).</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><p>If we have a very “large” panel of observations on each unit
(i.e., large <span class="math inline">\(T\)</span>), there is
sufficient “within” variation and we really don’t need to do any pooling
across units. So if <span class="math inline">\(N\)</span> is large and
<span class="math inline">\(T\)</span> is large, <span
class="math inline">\(\theta\)</span> will be close to 1, so the
estimates from a random effects regression will be similar to the fixed
effect regression.</p></li>
<li><p>Often <span class="math inline">\(0 &lt; \theta &lt; 1\)</span>,
hence the term “partial-pooling.”</p></li>
</ol>
<p>Essentially, when you fit a random effects regression,R/Stata
estimates <span class="math inline">\(\theta\)</span> and then plugs
that estimate it into the above model. When you fit a fixed effects
regression, Stata/R uses the demeaning approach–unless, of course, you
manually fit a dummy variable model.</p>
<p>Here is a nice <a
href="http://webhome.auburn.edu/~scj0014/Downloads/JP-PSR-2022.pdf">source</a>
on the topic. <a
href="https://graveja0.github.io/HPOL8539-F2022/blog/posts/quasi-demeaning.html">I
also constructed a blog post</a> based on our simulated DGP where I
estimate a random effects regression and compare it to a regression
based on quasi-demeaning. You’ll see there that the <span
class="math inline">\(\hat \tau\)</span> estimates these two approaches
yield are identical.</p>
</div>
<div id="section-exercise-9-correlated-random-effects"
class="section level2">
<h2>Exercise 9: Correlated Random Effects</h2>
<p>For our final exercise we will turn back to random effects estimation
and try to recover something that is useful. To preview where we are
going, what we will recover is effect estimates for <span
class="math inline">\(\hat \tau\)</span> that are <em>identical</em> to
what we obtain using fixed effects.<a href="#section-fn9"
class="footnote-ref" id="section-fnref9"><sup>9</sup></a></p>
<p>Recall that under a random effects approach, we assume the random
effects are drawn from a (normal) distribution and are independent of
the idiosyncratic error term <span
class="math inline">\(\epsilon_{it}\)</span>. Another way to say this is
that we assume the random effects are uncorrelated with other regressors
of interest (i.e., <span class="math inline">\(X_i\)</span> and <span
class="math inline">\(D_i\)</span>).</p>
<p>When unobserved heterogeneity exerts a confounding influence (i.e.,
<span class="math inline">\(\sigma_i\)</span> is correlated with both
<span class="math inline">\(D_i\)</span> and <span
class="math inline">\(Y_i\)</span>), we violate this assumption. Our
estimates of <span class="math inline">\(\hat \tau\)</span> are
therefore inconsistent. We saw this above in the random effects
regression sampling distribution for <span class="math inline">\(\hat
\tau\)</span> that was very far off from the truth.</p>
<p>In our initial approach we did not put a lot of structure on the
underlying “model” that describes the random effects. We simply assumed
they were random draws from a normal distribution with some defined
standard deviation.</p>
<p>For the unit-level random effect we have:</p>
<p><span class="math display">\[
\begin{aligned}
\delta_i &amp;\sim N(0,\sigma^2_i)
\end{aligned}
\]</span> For our final trick we are going to impose some additional
structure on the random effects. To ease the expositional burden, we’ll
again simplify a bit and base things off of a DGP that does not include
unobserved time-period specific heterogeneity:</p>
<p><span class="math display">\[
Y_{it} = \mathbf{X}_{it}&#39;\beta + \tau D_{it} + \delta_i+
\epsilon_{it} \\
\]</span> Let’s now assume</p>
<p><span class="math display">\[
\delta_i = \mathbf{\bar{X_i}}&#39;\eta + \lambda \bar{D_i} + \omega_i
\]</span></p>
<p>where <span class="math inline">\(\mathbf{\bar{X_i}}\)</span> is the
average of each unit’s values of <span
class="math inline">\(\mathbf{X_{it}}\)</span> across time periods <span
class="math inline">\(t\)</span>.</p>
<p>Borrowing the notation from the Panel Data section above, this
approach is equivalent to</p>
<p><span class="math display">\[
\begin{align}
\delta_i  &amp;\sim N(\rho,\sigma^2_i) \\
\rho &amp;= \mathbf{\bar{X_i}}&#39;\eta + \lambda \bar{D_i} \\
\omega_i &amp;\sim N(0,\sigma^2_i)
\end{align}
\]</span> Let’s now plug these representations of <span
class="math inline">\(\delta_i\)</span> into the DGP</p>
<p><span class="math display">\[
\begin{align}
Y_{it} &amp;= \mathbf{X}_{it}&#39;\beta + \tau D_{it} +
\overbrace{\delta_i}^{\mathbf{\bar{X_i}}&#39;\eta + \lambda \bar{D_i} +
\omega_i} + \epsilon_{it} \\
&amp;= \mathbf{X}_{it}&#39;\beta + \tau D_{it} +
\mathbf{\bar{X_i}}&#39;\eta + \lambda \bar{D_i} +\underbrace{\omega_i +
\epsilon_{it}}_{v_{it}} \\
v_{it} &amp;= \omega_i + \epsilon_{it} \\
\omega_i &amp;\sim N(0,\sigma^2_i)
\end{align}
\]</span> Essentially, what we’re doing here is allowing the unit-level
means <span class="math inline">\(\mathbf{\bar{X_i}}\)</span> and <span
class="math inline">\(\bar{D_i}\)</span> to capture any correlation
between <span class="math inline">\(\mathbf{X_i}\)</span> and <span
class="math inline">\(D_i\)</span> and the random effect <span
class="math inline">\(\delta_i\)</span>. We thus include these
unit-level means as additional RHS variables in the estimator to account
for this correlation, and otherwise fit the same random effects
regression as before.</p>
<p>A simple summary of the correlated random effects regression
follows:</p>
<ol style="list-style-type: decimal">
<li>We include all time-varying <span
class="math inline">\(\mathbf{X_{it}}\)</span>.</li>
<li>We include the time-varying treatment indicator <span
class="math inline">\(D_{it}\)</span>.</li>
<li>We include the each unit’s average for every <span
class="math inline">\(X_{it}\)</span>, i.e., <span
class="math inline">\((1/T)\sum_{t=1}^TX_{it}\)</span> for a balanced
panel.</li>
<li>We include each unit’s average <span
class="math inline">\(D_i\)</span>.</li>
<li>We include a random effect for <span
class="math inline">\(\omega_i\)</span>.</li>
</ol>
<p>Steps 1 and 2 we did before for random effects. Steps 3 and 4 are
new, but are easy to add!</p>
</div>
<div class="footnotes footnotes-end-of-section">
<hr />
<ol start="9">
<li id="section-fn9"><p>This will also become an important extension
when we try to estimate difference-in-differences using a nonlinear
model later in this course.<a href="#section-fnref9"
class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<div id="section-correlated-random-effects-r-code"
class="section level2">
<h2>Correlated Random Effects: R Code</h2>
<p>Again, we’ll expand on the exposition above to include random effects
for both units and time. This essentially amounts to adding group- and
time-level means to our standard random effects regression.</p>
<div class="tutorial-exercise" data-label="cre1" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="25">
<pre class="text"><code>prepare_cre &lt;- function(df) {
  df %&gt;% 
    group_by(t) %&gt;%
    mutate(d_bar_t = mean(d_i),
           x_bar_t = mean(x_i)) %&gt;%
    group_by(unit_id) %&gt;%
    mutate(d_bar_i = mean(d_i),
           x_bar_i = mean(x_i))
}

estimator_fn_cre &lt;- function(df) {
  suppressWarnings({suppressMessages({
    lmer(y_i ~ d_i + d_bar_t + d_bar_i + (1|t) + (1|unit_id), df)
  })})
}

set.seed(123)
params_panel %&gt;% 
  dgp_panel()  %&gt;% 
    prepare_cre() %&gt;% 
      estimator_fn_cre()</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Let’s verify this gives us an <em>identical</em> coefficient estimate
for <span class="math inline">\(\hat \tau\)</span> as the fixed effect
regression based on <code>feglm()</code>:</p>
<div class="tutorial-exercise" data-label="cre2" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="13">
<pre class="text"><code>estimator_fn_fe &lt;- function(df) {
  suppressWarnings({suppressMessages({
    feglm(y_i ~  d_i | t + unit_id, df, family = &quot;gaussian&quot;)
  })})
}

set.seed(123)
params_panel %&gt;% 
  dgp_panel()  %&gt;% 
    prepare_cre() %&gt;% 
      estimator_fn_fe()</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>It’s exactly the same. <strong>Correlated random effects yields
identical effect estimates as fixed effects regression</strong>.</p>
<p>To finish things out let’s verify the sampling distribution is
centered on the truth:</p>
<div class="tutorial-exercise" data-label="cre3" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="25">
<pre class="text"><code>disc_fn_cre &lt;- function(fit) {
  fit %&gt;% summary() %&gt;% pluck(&quot;coefficients&quot;) %&gt;%
    data.frame() %&gt;%
    rownames_to_column() %&gt;%
    janitor::clean_names() %&gt;%
    filter(rowname==&quot;d_i&quot;) %&gt;%
    pull(estimate) %&gt;%
    as.vector()
}

generate_estimate_discriminate_cre &lt;- function(params) {
  params %&gt;% # Step 1: Parameterize the problem
    dgp_panel() %&gt;%  # Step 2: Define the data generation process
      prepare_cre() %&gt;% # Step 2.5: Get the unit- and time-specific means 
      estimator_fn_cre() %&gt;%  # Step 3: Estimate 
        disc_fn_cre() %&gt;% # Step 4: Pull out what you need
        data.frame(tau_hat = .) # store the result as a data frame object
}


M = 100
result_cre &lt;- 1:M %&gt;% map_df(~generate_estimate_discriminate_cre(params_panel))
plot_sampling_distribution(result_cre$tau_hat, truth = params_panel$tau)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-next-steps-extending-difference-in-differences"
class="section level2">
<h2>Next Steps: Extending Difference-in-Differences</h2>
<p>We now have our “toolkit” of panel data estimators:</p>
<ol style="list-style-type: decimal">
<li>Pooled OLS</li>
<li>Random Effects (including Correlated Random Effects)</li>
<li>Fixed effects</li>
</ol>
<p>If you have been paying attention to the “DIDpocalypse” that has
occured within the social sciences over the last few years, you’ll know
that there are problems with fitting a two-way fixed effect estimator,
as we did here, to difference-in-difference settings with staggered
treatment rollout and/or treatment effect heterogeneity across treated
units.</p>
<p>It turns out that we can draw on this “toolbox” of approaches to
obtain difference-in-difference (DID) estimtates <strong>even in the
presence of treatment effect heterogeneity and staggered treatment
adoption</strong>. We just have to be careful and deliberate about how
we do so. We’ll cover how to do this next week. Our approach will also
set us up to consider nonlinear models (e.g., for binary or count
outcomes) the following week.</p>
<p>
<script type="application/shiny-prerendered" data-context="server-start">
library(learnr)
knitr::opts_chunk$set(echo = FALSE)

# load packages
library(learnr)
library(gradethis)
library(sortable)
library(tidyverse)
library(learnrhash) #devtools::install_github("rundel/learnrhash")
library(showtext)
library(googlesheets4)
library(mcreplicate)
library(knitr)
library(hrbrthemes)
library(here)
library(lme4)
library(progressr)
library(janitor)
library(future)
library(fixest)
library(broom)
lag <- dplyr::lag
#devtools::install_github("graveja0/HPOL8539PKG")
#library(HPOL8539PKG)
# devtools::load_all("../../HPOL8539PKG")


# don't echo chunks
knitr::opts_chunk$set(echo = FALSE)

# apply theme to ggplot
ggplot2::theme_set(theme_bw())

map_multicore <- function(.x, .f, ..., .id = NULL) {
  .f <- purrr::as_mapper(.f, ...)
  p <- progressor(steps = length(.x))
  f <- function(...) {
    p()
    .f(...)
  }
  furrr::future_map(.x, f, ..., .id = .id)
}

plot_sampling_distribution <- function(x,truth) {
  d <- density(x)
  p_df <- as_tibble(cbind(x = d$x, density = d$y))
  p_df %>%
    ggplot(aes(x = x, y = density)) + geom_line() +
    #hrbrthemes::theme_ipsum() +
    labs(x = "Estimate", y = "Density") +
    geom_vline(aes(xintercept = truth)) +
    annotate("text",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue("  \tMean: {formatC(mean(x),digits = 3, format='f')}\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\n   Truth: {truth}"), hjust = 0)
}

plot_cis <- function(x, K, truth) {
  res <- x %>% bind_rows(.id = "m") %>%
    as_tibble() %>%
    mutate(m = factor(m)) %>%
    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%
    mutate(truth = truth) %>%
    rowwise() %>%
    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%
    ungroup() %>%
    mutate(color = ifelse(covered ==1 , "","Rejected"))
  
  K = sample(res$m,100, replace =TRUE)
  res %>%
    filter(m %in% K) %>%
    ggplot() +
    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +
    #theme_ipsum() +
    scale_y_discrete(breaks = NULL) +
    geom_vline(aes(xintercept = truth)) +
    labs(title= glue("Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates"),
         y= "Sampling Iteration",x = "Estimate",
         subtitle= glue("{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth")) +
    scale_colour_manual(values = c("black","red")) +
    theme(legend.position = "none")
}

options("scipen" = 100, "digits" = 5)

#knitr::purl(here("Panel Data Methods I/Panel Data Methods I.Rmd"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::prepare_tutorial_state(session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::i18n_observe_tutorial_language(input, session)
</script>


<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::event_trigger(session, "session_stop")
      })
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ovb1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ovb1-code-editor`)), session)
output$`tutorial-exercise-ovb1-output` <- renderUI({
  `tutorial-exercise-ovb1-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "ovb1", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = NULL, 
    chunks = list(list(label = "ovb1", code = "##################################\n# Step 1: Parameterize the Problem\n##################################\nparams =list(\n  N = 1000,\n  mean_x_i = 2,\n  sd_x_i = 0.5,\n  beta = 1,\n  tau = 0.5,\n  sigma_sq_epsilon = 1\n)\n\n####################################################\n# Step 2: Define a Data Generation Process Function\n#####################################################\ndgp_df_u =function(params) {\n  with(params,{\n    df =\n      tibble(\n        # Covariate\n        x_i = rnorm(N, mean_x_i, sd_x_i),\n        # ADD UNOBSERVED HETEROGENEITY TERM\n        u_i = rnorm(N, mean = 0, sd = 1)) %>% \n        # Induce correlation between u_i and treatment;\n        # higher values of u_i make it more likely you're treated. \n        rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n        mutate(pr_treated = boot::inv.logit(u_i)) %>% \n        ungroup() %>%  # This undoes the rowwise \n        # Treatment indicator\n        mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n        mutate(epsilon_i = rnorm(N, mean = 0, sd = sigma_sq_epsilon)) %>% \n        # u_i is also in the DGP for y_i \n        mutate(y_i = beta * x_i + tau * d_i + u_i + epsilon_i) %>% \n        # because u_i is unobserved, we strip it from the \"observed\" data output. \n        select(-u_i)\n    return(df)\n  })\n}\n\n############################################\n# 3. Define and Apply an Estimation Function\n#############################################\nestimator_fn = function(df) {\n  out =\n    df %>% \n      lm(y_i ~ x_i + d_i, data = .)\n  return(out)\n}\n\n########################################\n# 4. Define the discriminator function \n# (For this exercise we want to extract tau-hat \n# i.e., the coefficient on treated)\n########################################\ndisc_fn = function(fit) {\n  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object\n  out =fit_ %>% \n    filter(term==\"d_i\") %>% \n    pull(estimate)\n  \n  return(out)\n}\n\n###############################################\n# 5. Define a compound function that executes\n# steps 1-4 based on the parameter inputs. \n###############################################\n\ngenerate_estimate_discriminate <- function(params) {\n  params %>% # Step 1: Parameterize the problem\n      dgp_df_u() %>%  # Step 2: Define the data generation process\n        estimator_fn() %>%  # Step 3: Estimate \n          disc_fn() %>% # Step 4: Pull out what you need\n            data.frame(tau_hat = .) # store the result as a data frame object\n}\n\n", 
        opts = list(label = "\"ovb1\"", echo = "TRUE", exercise = "TRUE", 
            exercise.lines = "60L"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "Panel-Data-Methods-I_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "ovb1", exercise = TRUE, exercise.lines = 60L, 
        code = c("##################################", "# Step 1: Parameterize the Problem", 
        "##################################", "params =list(", 
        "  N = 1000,", "  mean_x_i = 2,", "  sd_x_i = 0.5,", 
        "  beta = 1,", "  tau = 0.5,", "  sigma_sq_epsilon = 1", 
        ")", "", "####################################################", 
        "# Step 2: Define a Data Generation Process Function", 
        "#####################################################", 
        "dgp_df_u =function(params) {", "  with(params,{", "    df =", 
        "      tibble(", "        # Covariate", "        x_i = rnorm(N, mean_x_i, sd_x_i),", 
        "        # ADD UNOBSERVED HETEROGENEITY TERM", "        u_i = rnorm(N, mean = 0, sd = 1)) %>% ", 
        "        # Induce correlation between u_i and treatment;", 
        "        # higher values of u_i make it more likely you're treated. ", 
        "        rowwise() %>% # This allows us to get each value's pr_treated in the line below. ", 
        "        mutate(pr_treated = boot::inv.logit(u_i)) %>% ", 
        "        ungroup() %>%  # This undoes the rowwise ", 
        "        # Treatment indicator", "        mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% ", 
        "        mutate(epsilon_i = rnorm(N, mean = 0, sd = sigma_sq_epsilon)) %>% ", 
        "        # u_i is also in the DGP for y_i ", "        mutate(y_i = beta * x_i + tau * d_i + u_i + epsilon_i) %>% ", 
        "        # because u_i is unobserved, we strip it from the \"observed\" data output. ", 
        "        select(-u_i)", "    return(df)", "  })", "}", 
        "", "############################################", "# 3. Define and Apply an Estimation Function", 
        "#############################################", "estimator_fn = function(df) {", 
        "  out =", "    df %>% ", "      lm(y_i ~ x_i + d_i, data = .)", 
        "  return(out)", "}", "", "########################################", 
        "# 4. Define the discriminator function ", "# (For this exercise we want to extract tau-hat ", 
        "# i.e., the coefficient on treated)", "########################################", 
        "disc_fn = function(fit) {", "  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object", 
        "  out =fit_ %>% ", "    filter(term==\"d_i\") %>% ", 
        "    pull(estimate)", "  ", "  return(out)", "}", "", 
        "###############################################", "# 5. Define a compound function that executes", 
        "# steps 1-4 based on the parameter inputs. ", "###############################################", 
        "", "generate_estimate_discriminate <- function(params) {", 
        "  params %>% # Step 1: Parameterize the problem", "      dgp_df_u() %>%  # Step 2: Define the data generation process", 
        "        estimator_fn() %>%  # Step 3: Estimate ", "          disc_fn() %>% # Step 4: Pull out what you need", 
        "            data.frame(tau_hat = .) # store the result as a data frame object", 
        "}", "", ""), out.width.px = 624, out.height.px = 384, 
        params.src = "ovb1", fig.num = 0, exercise.df_print = "paged"), 
    engine = "r", version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-mc_ovb-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-mc_ovb-code-editor`)), session)
output$`tutorial-exercise-mc_ovb-output` <- renderUI({
  `tutorial-exercise-mc_ovb-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "mc_ovb", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "##################################\n# Step 1: Parameterize the Problem\n##################################\nparams =list(\n  N = 1000,\n  mean_x_i = 2,\n  sd_x_i = 0.5,\n  beta = 1,\n  tau = 0.5,\n  sigma_sq_epsilon = 1\n)\n\n####################################################\n# Step 2: Define a Data Generation Process Function\n#####################################################\ndgp_df_u =function(params) {\n  with(params,{\n    df =\n      tibble(\n        # Covariate\n        x_i = rnorm(N, mean_x_i, sd_x_i),\n        # ADD UNOBSERVED HETEROGENEITY TERM\n        u_i = rnorm(N, mean = 0, sd = 1)) %>% \n        # Induce correlation between u_i and treatment;\n        # higher values of u_i make it more likely you're treated. \n        rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n        mutate(pr_treated = boot::inv.logit(u_i)) %>% \n        ungroup() %>%  # This undoes the rowwise \n        # Treatment indicator\n        mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n        mutate(epsilon_i = rnorm(N, mean = 0, sd = sigma_sq_epsilon)) %>% \n        # u_i is also in the DGP for y_i \n        mutate(y_i = beta * x_i + tau * d_i + u_i + epsilon_i) %>% \n        # because u_i is unobserved, we strip it from the \"observed\" data output. \n        select(-u_i)\n    return(df)\n  })\n}\n\n############################################\n# 3. Define and Apply an Estimation Function\n#############################################\nestimator_fn = function(df) {\n  out =\n    df %>% \n      lm(y_i ~ x_i + d_i, data = .)\n  return(out)\n}\n\n########################################\n# 4. Define the discriminator function \n# (For this exercise we want to extract tau-hat \n# i.e., the coefficient on treated)\n########################################\ndisc_fn = function(fit) {\n  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object\n  out =fit_ %>% \n    filter(term==\"d_i\") %>% \n    pull(estimate)\n  \n  return(out)\n}\n\n###############################################\n# 5. Define a compound function that executes\n# steps 1-4 based on the parameter inputs. \n###############################################\n\ngenerate_estimate_discriminate <- function(params) {\n  params %>% # Step 1: Parameterize the problem\n      dgp_df_u() %>%  # Step 2: Define the data generation process\n        estimator_fn() %>%  # Step 3: Estimate \n          disc_fn() %>% # Step 4: Pull out what you need\n            data.frame(tau_hat = .) # store the result as a data frame object\n}\n\n", 
    chunks = list(list(label = "ovb1", code = "##################################\n# Step 1: Parameterize the Problem\n##################################\nparams =list(\n  N = 1000,\n  mean_x_i = 2,\n  sd_x_i = 0.5,\n  beta = 1,\n  tau = 0.5,\n  sigma_sq_epsilon = 1\n)\n\n####################################################\n# Step 2: Define a Data Generation Process Function\n#####################################################\ndgp_df_u =function(params) {\n  with(params,{\n    df =\n      tibble(\n        # Covariate\n        x_i = rnorm(N, mean_x_i, sd_x_i),\n        # ADD UNOBSERVED HETEROGENEITY TERM\n        u_i = rnorm(N, mean = 0, sd = 1)) %>% \n        # Induce correlation between u_i and treatment;\n        # higher values of u_i make it more likely you're treated. \n        rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n        mutate(pr_treated = boot::inv.logit(u_i)) %>% \n        ungroup() %>%  # This undoes the rowwise \n        # Treatment indicator\n        mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n        mutate(epsilon_i = rnorm(N, mean = 0, sd = sigma_sq_epsilon)) %>% \n        # u_i is also in the DGP for y_i \n        mutate(y_i = beta * x_i + tau * d_i + u_i + epsilon_i) %>% \n        # because u_i is unobserved, we strip it from the \"observed\" data output. \n        select(-u_i)\n    return(df)\n  })\n}\n\n############################################\n# 3. Define and Apply an Estimation Function\n#############################################\nestimator_fn = function(df) {\n  out =\n    df %>% \n      lm(y_i ~ x_i + d_i, data = .)\n  return(out)\n}\n\n########################################\n# 4. Define the discriminator function \n# (For this exercise we want to extract tau-hat \n# i.e., the coefficient on treated)\n########################################\ndisc_fn = function(fit) {\n  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object\n  out =fit_ %>% \n    filter(term==\"d_i\") %>% \n    pull(estimate)\n  \n  return(out)\n}\n\n###############################################\n# 5. Define a compound function that executes\n# steps 1-4 based on the parameter inputs. \n###############################################\n\ngenerate_estimate_discriminate <- function(params) {\n  params %>% # Step 1: Parameterize the problem\n      dgp_df_u() %>%  # Step 2: Define the data generation process\n        estimator_fn() %>%  # Step 3: Estimate \n          disc_fn() %>% # Step 4: Pull out what you need\n            data.frame(tau_hat = .) # store the result as a data frame object\n}\n\n", 
        opts = list(label = "\"ovb1\"", echo = "TRUE", exercise = "TRUE", 
            exercise.lines = "60L"), engine = "r"), list(label = "mc_ovb", 
        code = "\n# Monte Carlo simulation based on 100 different realizations of the DGP:\nM = 100\nresult_lm <- 1:M %>% map_df(~generate_estimate_discriminate(params))\n\nplot_sampling_distribution(result_lm$tau_hat, truth = params$tau)", 
        opts = list(label = "\"mc_ovb\"", exercise.setup = "\"ovb1\"", 
            echo = "TRUE", exercise = "TRUE", exercise.lines = "7L"), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "Panel-Data-Methods-I_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "mc_ovb", exercise.setup = "ovb1", exercise = TRUE, 
        exercise.lines = 7L, code = c("", "# Monte Carlo simulation based on 100 different realizations of the DGP:", 
        "M = 100", "result_lm <- 1:M %>% map_df(~generate_estimate_discriminate(params))", 
        "", "plot_sampling_distribution(result_lm$tau_hat, truth = params$tau)"
        ), out.width.px = 624, out.height.px = 384, params.src = "mc_ovb, exercise.setup = \"ovb1\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-dgp_panel_setup-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-dgp_panel_setup-code-editor`)), session)
output$`tutorial-exercise-dgp_panel_setup-output` <- renderUI({
  `tutorial-exercise-dgp_panel_setup-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "dgp_panel_setup", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = NULL, 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r")), 
    code_check = NULL, error_check = NULL, check = NULL, solution = NULL, 
    tests = NULL, options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "Panel-Data-Methods-I_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "dgp_panel_setup", exercise = TRUE, exercise.lines = 45L, 
        code = c("params_panel <- list(", "  N = 1000,", "  T = 2,", 
        "  tx_time = 2, ", "  rho_t = 0.8,", "  beta_0 = 0.5,", 
        "  beta_1 = 2,", "  tau = 0.5,", "  p_d = 0.5", ")", 
        "", "dgp_panel <- function(params) {", "  with(params, {", 
        "", "    # Time effects", "    t_ <-", "      data.frame(t = 1:T,", 
        "                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())", 
        "", "    # Individual measures and effects", "    i_ <-", 
        "      data.frame(", "        unit_id = 1:N,", "        x_i = rnorm(N, mean = 0, sd = 1),", 
        "        u_i = rnorm(N, mean = 0, sd = 1)) %>%", "      rowwise() %>% # This allows us to get each value's pr_treated in the line below. ", 
        "      mutate(pr_treated = boot::inv.logit(u_i)) %>% ", 
        "      ungroup() %>%  # This undoes the rowwise ", "      # Treatment indicator", 
        "      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% ", 
        "      ungroup()", "", "    crossing(unit_id = i_$unit_id,t = t_$t) %>%", 
        "      left_join(i_,\"unit_id\") %>%", "      left_join(t_,\"t\") %>%", 
        "      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%", "      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))", 
        "  })", "}", "", "params_panel %>% ", "  dgp_panel()", 
        ""), out.width.px = 624, out.height.px = 384, params.src = "dgp_panel_setup", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-pooledOLS1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-pooledOLS1-code-editor`)), session)
output$`tutorial-exercise-pooledOLS1-output` <- renderUI({
  `tutorial-exercise-pooledOLS1-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "pooledOLS1", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "pooledOLS1", code = "estimator_fn_pols <- function(df) {\n  lm(y_i ~ x_i + d_i, data = df)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    estimator_fn_pols()\n", 
            opts = list(label = "\"pooledOLS1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", `exercise-setup` = "\"simple1_dgp\"", 
                exercise.lines = "9L"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "Panel-Data-Methods-I_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "pooledOLS1", exercise.setup = "dgp_panel_setup", 
        exercise = TRUE, `exercise-setup` = "simple1_dgp", exercise.lines = 9L, 
        code = c("estimator_fn_pols <- function(df) {", "  lm(y_i ~ x_i + d_i, data = df)", 
        "}", "", "params_panel %>% ", "  dgp_panel() %>% ", "    estimator_fn_pols()", 
        ""), out.width.px = 624, out.height.px = 384, params.src = "pooledOLS1, exercise.setup=\"dgp_panel_setup\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-pooledOLS2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-pooledOLS2-code-editor`)), session)
output$`tutorial-exercise-pooledOLS2-output` <- renderUI({
  `tutorial-exercise-pooledOLS2-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "pooledOLS2", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n\nestimator_fn_pols <- function(df) {\n  lm(y_i ~ x_i + d_i, data = df)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    estimator_fn_pols()\n", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "pooledOLS1", code = "estimator_fn_pols <- function(df) {\n  lm(y_i ~ x_i + d_i, data = df)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    estimator_fn_pols()\n", 
            opts = list(label = "\"pooledOLS1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", `exercise-setup` = "\"simple1_dgp\"", 
                exercise.lines = "9L"), engine = "r"), list(label = "pooledOLS2", 
            code = "# Define a discrimination function for the POLS estimator \ndisc_fn_pols = function(fit) {\n  fit_ =broom::tidy(fit)   \n  out =fit_ %>% \n    filter(term==\"d_i\") %>% \n    pull(estimate)\n  return(out)\n}\n\ngenerate_estimate_discriminate_pols <- function(params) {\n  params %>% # Step 1: Parameterize the problem\n      dgp_panel() %>%  # Step 2: DGP\n        estimator_fn_pols() %>%  # Step 3: Estimate \n          disc_fn_pols() %>% # Step 4: Coefficient of interest\n            data.frame(tau_hat = .) # Store as data fram\n}\n\nM = 100\nresult_pols <- 1:M %>% map_df(~generate_estimate_discriminate_pols(params_panel))\nplot_sampling_distribution(result_pols$tau_hat, truth = params_panel$tau)", 
            opts = list(label = "\"pooledOLS2\"", exercise.setup = "\"pooledOLS1\"", 
                echo = "TRUE", exercise = "TRUE", `exercise-setup` = "\"simple1_dgp\"", 
                exercise.lines = "22L"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "Panel-Data-Methods-I_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "pooledOLS2", exercise.setup = "pooledOLS1", 
        exercise = TRUE, `exercise-setup` = "simple1_dgp", exercise.lines = 22L, 
        code = c("# Define a discrimination function for the POLS estimator ", 
        "disc_fn_pols = function(fit) {", "  fit_ =broom::tidy(fit)   ", 
        "  out =fit_ %>% ", "    filter(term==\"d_i\") %>% ", 
        "    pull(estimate)", "  return(out)", "}", "", "generate_estimate_discriminate_pols <- function(params) {", 
        "  params %>% # Step 1: Parameterize the problem", "      dgp_panel() %>%  # Step 2: DGP", 
        "        estimator_fn_pols() %>%  # Step 3: Estimate ", 
        "          disc_fn_pols() %>% # Step 4: Coefficient of interest", 
        "            data.frame(tau_hat = .) # Store as data fram", 
        "}", "", "M = 100", "result_pols <- 1:M %>% map_df(~generate_estimate_discriminate_pols(params_panel))", 
        "plot_sampling_distribution(result_pols$tau_hat, truth = params_panel$tau)"
        ), out.width.px = 624, out.height.px = 384, params.src = "pooledOLS2, exercise.setup=\"pooledOLS1\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-re1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-re1-code-editor`)), session)
output$`tutorial-exercise-re1-output` <- renderUI({
  `tutorial-exercise-re1-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "re1", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "re1", code = "\nestimator_fn_re <- function(df) {\n   lmer(y_i ~ x_i+ d_i + (1|unit_id) + (1|t), df)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    estimator_fn_re()\n", 
            opts = list(label = "\"re1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", exercise.eval = "FALSE", 
                eval = "TRUE", exercise.lines = "11L"), engine = "r")), 
    code_check = NULL, error_check = NULL, check = NULL, solution = NULL, 
    tests = NULL, options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "Panel-Data-Methods-I_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "re1", exercise.setup = "dgp_panel_setup", exercise = TRUE, 
        exercise.eval = FALSE, exercise.lines = 11L, code = c("", 
        "estimator_fn_re <- function(df) {", "   lmer(y_i ~ x_i+ d_i + (1|unit_id) + (1|t), df)", 
        "}", "", "params_panel %>% ", "  dgp_panel() %>% ", "    estimator_fn_re()", 
        ""), out.width.px = 624, out.height.px = 384, params.src = "re1, exercise.setup=\"dgp_panel_setup\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-re2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-re2-code-editor`)), session)
output$`tutorial-exercise-re2-output` <- renderUI({
  `tutorial-exercise-re2-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "re2", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n\n\nestimator_fn_re <- function(df) {\n   lmer(y_i ~ x_i+ d_i + (1|unit_id) + (1|t), df)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    estimator_fn_re()\n", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "re1", code = "\nestimator_fn_re <- function(df) {\n   lmer(y_i ~ x_i+ d_i + (1|unit_id) + (1|t), df)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    estimator_fn_re()\n", 
            opts = list(label = "\"re1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", exercise.eval = "FALSE", 
                eval = "TRUE", exercise.lines = "11L"), engine = "r"), 
        list(label = "re2", code = "# Define a discriminator function\ndisc_fn_re <- function(fit) {\n  fit %>% summary() %>% pluck(\"coefficients\") %>%\n    data.frame() %>%\n    rownames_to_column() %>%\n    janitor::clean_names() %>%\n    filter(rowname==\"d_i\") %>%\n    pull(estimate) %>%\n    as.vector()\n}\n\n# Bundle it all together in one function. \ngenerate_estimate_discriminate_re <- function(params) {\n  suppressWarnings({\n    suppressMessages({\n      params %>% # Step 1: Parameterize the problem\n        dgp_panel() %>%  # Step 2: Define the data generation process\n          estimator_fn_re() %>%  # Step 3: Estimate \n            disc_fn_re() %>% # Step 4: Pull out what you need\n              data.frame(tau_hat = .) # store the result as a data frame object\n    })\n  })\n}\n\n# Run it 100 times!\nM = 100\nresult_re <- 1:M %>% map_df(~generate_estimate_discriminate_re(params_panel))\n\nplot_sampling_distribution(result_re$tau_hat, truth = params_panel$tau)", 
            opts = list(label = "\"re2\"", exercise.setup = "\"re1\"", 
                echo = "TRUE", exercise = "TRUE", `exercise-setup` = "\"simple1_dgp\"", 
                exercise.lines = "31L"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "Panel-Data-Methods-I_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "re2", exercise.setup = "re1", exercise = TRUE, 
        `exercise-setup` = "simple1_dgp", exercise.lines = 31L, 
        code = c("# Define a discriminator function", "disc_fn_re <- function(fit) {", 
        "  fit %>% summary() %>% pluck(\"coefficients\") %>%", 
        "    data.frame() %>%", "    rownames_to_column() %>%", 
        "    janitor::clean_names() %>%", "    filter(rowname==\"d_i\") %>%", 
        "    pull(estimate) %>%", "    as.vector()", "}", "", 
        "# Bundle it all together in one function. ", "generate_estimate_discriminate_re <- function(params) {", 
        "  suppressWarnings({", "    suppressMessages({", "      params %>% # Step 1: Parameterize the problem", 
        "        dgp_panel() %>%  # Step 2: Define the data generation process", 
        "          estimator_fn_re() %>%  # Step 3: Estimate ", 
        "            disc_fn_re() %>% # Step 4: Pull out what you need", 
        "              data.frame(tau_hat = .) # store the result as a data frame object", 
        "    })", "  })", "}", "", "# Run it 100 times!", "M = 100", 
        "result_re <- 1:M %>% map_df(~generate_estimate_discriminate_re(params_panel))", 
        "", "plot_sampling_distribution(result_re$tau_hat, truth = params_panel$tau)"
        ), out.width.px = 624, out.height.px = 384, params.src = "re2, exercise.setup=\"re1\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-dummy1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-dummy1-code-editor`)), session)
output$`tutorial-exercise-dummy1-output` <- renderUI({
  `tutorial-exercise-dummy1-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "dummy1", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "dummy1", code = "estimator_fn_dummy <- function(df) {\n  lm(y_i ~ d_i + factor(t) + factor(unit_id), df)\n}\n\nfit_dummy <- \n  params_panel %>% \n    dgp_panel() %>% \n      estimator_fn_dummy()\n\nfit_dummy %>% \n  broom::tidy() ", 
            opts = list(label = "\"dummy1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", exercise.eval = "FALSE", 
                exercise.lines = "15L"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "Panel-Data-Methods-I_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "dummy1", exercise.setup = "dgp_panel_setup", 
        exercise = TRUE, exercise.eval = FALSE, exercise.lines = 15L, 
        code = c("estimator_fn_dummy <- function(df) {", "  lm(y_i ~ d_i + factor(t) + factor(unit_id), df)", 
        "}", "", "fit_dummy <- ", "  params_panel %>% ", "    dgp_panel() %>% ", 
        "      estimator_fn_dummy()", "", "fit_dummy %>% ", "  broom::tidy() "
        ), out.width.px = 624, out.height.px = 384, params.src = "dummy1, exercise.setup=\"dgp_panel_setup\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-fistdiff1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-fistdiff1-code-editor`)), session)
output$`tutorial-exercise-fistdiff1-output` <- renderUI({
  `tutorial-exercise-fistdiff1-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "fistdiff1", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "fistdiff1", code = "construct_first_diff <- function(df) {\n  df_ <- \n    df %>% \n      arrange(unit_id,t) %>% \n      group_by(unit_id) %>% \n      mutate(y_fd = y_i - lag(y_i),\n             x_fd = x_i - lag(x_i),\n             d_fd = d_i - lag(d_i)) %>% \n      filter(t==2)\n  return(df_)\n}\n\nestimate_first_diff <- function(df) {\n  lm(y_fd ~ d_fd , data = df)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    construct_first_diff() %>% \n      estimate_first_diff() %>% \n        summary() \n", 
            opts = list(label = "\"fistdiff1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "23L"), 
            engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "Panel-Data-Methods-I_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "fistdiff1", exercise.setup = "dgp_panel_setup", 
        exercise = TRUE, exercise.lines = 23L, code = c("construct_first_diff <- function(df) {", 
        "  df_ <- ", "    df %>% ", "      arrange(unit_id,t) %>% ", 
        "      group_by(unit_id) %>% ", "      mutate(y_fd = y_i - lag(y_i),", 
        "             x_fd = x_i - lag(x_i),", "             d_fd = d_i - lag(d_i)) %>% ", 
        "      filter(t==2)", "  return(df_)", "}", "", "estimate_first_diff <- function(df) {", 
        "  lm(y_fd ~ d_fd , data = df)", "}", "", "params_panel %>% ", 
        "  dgp_panel() %>% ", "    construct_first_diff() %>% ", 
        "      estimate_first_diff() %>% ", "        summary() ", 
        ""), out.width.px = 624, out.height.px = 384, params.src = "fistdiff1, exercise.setup=\"dgp_panel_setup\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-fistdiff2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-fistdiff2-code-editor`)), session)
output$`tutorial-exercise-fistdiff2-output` <- renderUI({
  `tutorial-exercise-fistdiff2-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "fistdiff2", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n\nconstruct_first_diff <- function(df) {\n  df_ <- \n    df %>% \n      arrange(unit_id,t) %>% \n      group_by(unit_id) %>% \n      mutate(y_fd = y_i - lag(y_i),\n             x_fd = x_i - lag(x_i),\n             d_fd = d_i - lag(d_i)) %>% \n      filter(t==2)\n  return(df_)\n}\n\nestimate_first_diff <- function(df) {\n  lm(y_fd ~ d_fd , data = df)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    construct_first_diff() %>% \n      estimate_first_diff() %>% \n        summary() \n", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "fistdiff1", code = "construct_first_diff <- function(df) {\n  df_ <- \n    df %>% \n      arrange(unit_id,t) %>% \n      group_by(unit_id) %>% \n      mutate(y_fd = y_i - lag(y_i),\n             x_fd = x_i - lag(x_i),\n             d_fd = d_i - lag(d_i)) %>% \n      filter(t==2)\n  return(df_)\n}\n\nestimate_first_diff <- function(df) {\n  lm(y_fd ~ d_fd , data = df)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    construct_first_diff() %>% \n      estimate_first_diff() %>% \n        summary() \n", 
            opts = list(label = "\"fistdiff1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "23L"), 
            engine = "r"), list(label = "fistdiff2", code = "disc_fn_first_diff = function(fit) {\n  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object\n  out =fit_ %>% \n    filter(term==\"d_fd\") %>% \n    pull(estimate)\n  \n  return(out)\n}\n\ngenerate_estimate_discriminate_first_diff <- function(params) {\n  params_panel %>% \n    dgp_panel() %>% \n      construct_first_diff() %>% \n        estimate_first_diff() %>% \n          disc_fn_first_diff() %>% \n              data.frame(tau_hat = .) # store the result as a data frame object\n}\n\n \nM = 100\nresult_first_diff <- \n  1:M %>% \n  map_df(~generate_estimate_discriminate_first_diff(params_panel)) \n\nplot_sampling_distribution(result_first_diff$tau_hat, truth = params_panel$tau)\n", 
            opts = list(label = "\"fistdiff2\"", exercise.setup = "\"fistdiff1\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "30L"), 
            engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "Panel-Data-Methods-I_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "fistdiff2", exercise.setup = "fistdiff1", exercise = TRUE, 
        exercise.lines = 30L, code = c("disc_fn_first_diff = function(fit) {", 
        "  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object", 
        "  out =fit_ %>% ", "    filter(term==\"d_fd\") %>% ", 
        "    pull(estimate)", "  ", "  return(out)", "}", "", 
        "generate_estimate_discriminate_first_diff <- function(params) {", 
        "  params_panel %>% ", "    dgp_panel() %>% ", "      construct_first_diff() %>% ", 
        "        estimate_first_diff() %>% ", "          disc_fn_first_diff() %>% ", 
        "              data.frame(tau_hat = .) # store the result as a data frame object", 
        "}", "", " ", "M = 100", "result_first_diff <- ", "  1:M %>% ", 
        "  map_df(~generate_estimate_discriminate_first_diff(params_panel)) ", 
        "", "plot_sampling_distribution(result_first_diff$tau_hat, truth = params_panel$tau)", 
        ""), out.width.px = 624, out.height.px = 384, params.src = "fistdiff2, exercise.setup=\"fistdiff1\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-demean1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-demean1-code-editor`)), session)
output$`tutorial-exercise-demean1-output` <- renderUI({
  `tutorial-exercise-demean1-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "demean1", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "demean1", code = "demean_data <- function(df) {\n  df_ <- \n    df %>% \n      mutate(\n            # Step 1: Add in the global mean.\n            y_dm = y_i + mean(y_i),\n            d_dm = d_i + mean(d_i)) %>% \n            # Step 2: Subtract out the time-period means\n            group_by(t) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_i)) %>% \n            # Step 3: Subtract out the unit-level means. \n            group_by(unit_id) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_dm)) %>% \n            ungroup()\n\n  return(df_)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() ", 
            opts = list(label = "\"demean1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "25L"), 
            engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "Panel-Data-Methods-I_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "demean1", exercise.setup = "dgp_panel_setup", 
        exercise = TRUE, exercise.lines = 25L, code = c("demean_data <- function(df) {", 
        "  df_ <- ", "    df %>% ", "      mutate(", "            # Step 1: Add in the global mean.", 
        "            y_dm = y_i + mean(y_i),", "            d_dm = d_i + mean(d_i)) %>% ", 
        "            # Step 2: Subtract out the time-period means", 
        "            group_by(t) %>% ", "            mutate(y_dm = y_dm - mean(y_dm),", 
        "            d_dm = d_dm - mean(d_i)) %>% ", "            # Step 3: Subtract out the unit-level means. ", 
        "            group_by(unit_id) %>% ", "            mutate(y_dm = y_dm - mean(y_dm),", 
        "            d_dm = d_dm - mean(d_dm)) %>% ", "            ungroup()", 
        "", "  return(df_)", "}", "", "params_panel %>% ", "  dgp_panel() %>% ", 
        "    demean_data() "), out.width.px = 624, out.height.px = 384, 
        params.src = "demean1,exercise.setup=\"dgp_panel_setup\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-demean2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-demean2-code-editor`)), session)
output$`tutorial-exercise-demean2-output` <- renderUI({
  `tutorial-exercise-demean2-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "demean2", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n\ndemean_data <- function(df) {\n  df_ <- \n    df %>% \n      mutate(\n            # Step 1: Add in the global mean.\n            y_dm = y_i + mean(y_i),\n            d_dm = d_i + mean(d_i)) %>% \n            # Step 2: Subtract out the time-period means\n            group_by(t) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_i)) %>% \n            # Step 3: Subtract out the unit-level means. \n            group_by(unit_id) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_dm)) %>% \n            ungroup()\n\n  return(df_)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() ", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "demean1", code = "demean_data <- function(df) {\n  df_ <- \n    df %>% \n      mutate(\n            # Step 1: Add in the global mean.\n            y_dm = y_i + mean(y_i),\n            d_dm = d_i + mean(d_i)) %>% \n            # Step 2: Subtract out the time-period means\n            group_by(t) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_i)) %>% \n            # Step 3: Subtract out the unit-level means. \n            group_by(unit_id) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_dm)) %>% \n            ungroup()\n\n  return(df_)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() ", 
            opts = list(label = "\"demean1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "25L"), 
            engine = "r"), list(label = "demean2", code = "estimator_fn_dm <- function(df) {\n  lm(y_dm ~ d_dm   , data = df)\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() %>% \n      estimator_fn_dm()", 
            opts = list(label = "\"demean2\"", exercise.setup = "\"demean1\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "10L"), 
            engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "Panel-Data-Methods-I_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "demean2", exercise.setup = "demean1", exercise = TRUE, 
        exercise.lines = 10L, code = c("estimator_fn_dm <- function(df) {", 
        "  lm(y_dm ~ d_dm   , data = df)", "}", "", "set.seed(123)", 
        "params_panel %>% ", "  dgp_panel() %>% ", "    demean_data() %>% ", 
        "      estimator_fn_dm()"), out.width.px = 624, out.height.px = 384, 
        params.src = "demean2,exercise.setup=\"demean1\"", fig.num = 0, 
        exercise.df_print = "paged"), engine = "r", version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-demean3-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-demean3-code-editor`)), session)
output$`tutorial-exercise-demean3-output` <- renderUI({
  `tutorial-exercise-demean3-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "demean3", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n\ndemean_data <- function(df) {\n  df_ <- \n    df %>% \n      mutate(\n            # Step 1: Add in the global mean.\n            y_dm = y_i + mean(y_i),\n            d_dm = d_i + mean(d_i)) %>% \n            # Step 2: Subtract out the time-period means\n            group_by(t) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_i)) %>% \n            # Step 3: Subtract out the unit-level means. \n            group_by(unit_id) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_dm)) %>% \n            ungroup()\n\n  return(df_)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() \nestimator_fn_dm <- function(df) {\n  lm(y_dm ~ d_dm   , data = df)\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() %>% \n      estimator_fn_dm()", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "demean1", code = "demean_data <- function(df) {\n  df_ <- \n    df %>% \n      mutate(\n            # Step 1: Add in the global mean.\n            y_dm = y_i + mean(y_i),\n            d_dm = d_i + mean(d_i)) %>% \n            # Step 2: Subtract out the time-period means\n            group_by(t) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_i)) %>% \n            # Step 3: Subtract out the unit-level means. \n            group_by(unit_id) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_dm)) %>% \n            ungroup()\n\n  return(df_)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() ", 
            opts = list(label = "\"demean1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "25L"), 
            engine = "r"), list(label = "demean2", code = "estimator_fn_dm <- function(df) {\n  lm(y_dm ~ d_dm   , data = df)\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() %>% \n      estimator_fn_dm()", 
            opts = list(label = "\"demean2\"", exercise.setup = "\"demean1\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "10L"), 
            engine = "r"), list(label = "demean3", code = "estimator_fn_dm2 <- function(df) {\n  feglm(y_i ~  d_i | t + unit_id, df, family = \"gaussian\")\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() %>% \n      estimator_fn_dm2()", 
            opts = list(label = "\"demean3\"", exercise.setup = "\"demean2\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "11L"), 
            engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "Panel-Data-Methods-I_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "demean3", exercise.setup = "demean2", exercise = TRUE, 
        exercise.lines = 11L, code = c("estimator_fn_dm2 <- function(df) {", 
        "  feglm(y_i ~  d_i | t + unit_id, df, family = \"gaussian\")", 
        "}", "", "set.seed(123)", "params_panel %>% ", "  dgp_panel() %>% ", 
        "    demean_data() %>% ", "      estimator_fn_dm2()"), 
        out.width.px = 624, out.height.px = 384, params.src = "demean3,exercise.setup=\"demean2\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-demean4-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-demean4-code-editor`)), session)
output$`tutorial-exercise-demean4-output` <- renderUI({
  `tutorial-exercise-demean4-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "demean4", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n\ndemean_data <- function(df) {\n  df_ <- \n    df %>% \n      mutate(\n            # Step 1: Add in the global mean.\n            y_dm = y_i + mean(y_i),\n            d_dm = d_i + mean(d_i)) %>% \n            # Step 2: Subtract out the time-period means\n            group_by(t) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_i)) %>% \n            # Step 3: Subtract out the unit-level means. \n            group_by(unit_id) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_dm)) %>% \n            ungroup()\n\n  return(df_)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() \nestimator_fn_dm <- function(df) {\n  lm(y_dm ~ d_dm   , data = df)\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() %>% \n      estimator_fn_dm()\nestimator_fn_dm2 <- function(df) {\n  feglm(y_i ~  d_i | t + unit_id, df, family = \"gaussian\")\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() %>% \n      estimator_fn_dm2()", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "demean1", code = "demean_data <- function(df) {\n  df_ <- \n    df %>% \n      mutate(\n            # Step 1: Add in the global mean.\n            y_dm = y_i + mean(y_i),\n            d_dm = d_i + mean(d_i)) %>% \n            # Step 2: Subtract out the time-period means\n            group_by(t) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_i)) %>% \n            # Step 3: Subtract out the unit-level means. \n            group_by(unit_id) %>% \n            mutate(y_dm = y_dm - mean(y_dm),\n            d_dm = d_dm - mean(d_dm)) %>% \n            ungroup()\n\n  return(df_)\n}\n\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() ", 
            opts = list(label = "\"demean1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "25L"), 
            engine = "r"), list(label = "demean2", code = "estimator_fn_dm <- function(df) {\n  lm(y_dm ~ d_dm   , data = df)\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() %>% \n      estimator_fn_dm()", 
            opts = list(label = "\"demean2\"", exercise.setup = "\"demean1\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "10L"), 
            engine = "r"), list(label = "demean3", code = "estimator_fn_dm2 <- function(df) {\n  feglm(y_i ~  d_i | t + unit_id, df, family = \"gaussian\")\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel() %>% \n    demean_data() %>% \n      estimator_fn_dm2()", 
            opts = list(label = "\"demean3\"", exercise.setup = "\"demean2\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "11L"), 
            engine = "r"), list(label = "demean4", code = "# Define a discriminator function that collects estimates of \\hat \\tau\ndisc_fn_dm = function(fit) {\n  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object\n  out =fit_ %>% \n    filter(term==\"d_dm\") %>% \n    pull(estimate)\n  \n  return(out)\n}\n\n# Bundle it all together in a single function. \ngenerate_estimate_discriminate_dm <- function(params) {\n  params %>% \n    dgp_panel() %>% \n        demean_data() %>% \n            estimator_fn_dm() %>% \n              disc_fn_dm() %>% \n                data.frame(tau_hat = .) # store the result as a data frame object\n}\n\nM = 100\nresult_dm <- \n  1:M %>% \n  map_df(~generate_estimate_discriminate_dm(params_panel)) \n\nplot_sampling_distribution(result_dm$tau_hat, truth = params_panel$tau)\n", 
            opts = list(label = "\"demean4\"", exercise.setup = "\"demean3\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "28L"), 
            engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "Panel-Data-Methods-I_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "demean4", exercise.setup = "demean3", exercise = TRUE, 
        exercise.lines = 28L, code = c("# Define a discriminator function that collects estimates of \\hat \\tau", 
        "disc_fn_dm = function(fit) {", "  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object", 
        "  out =fit_ %>% ", "    filter(term==\"d_dm\") %>% ", 
        "    pull(estimate)", "  ", "  return(out)", "}", "", 
        "# Bundle it all together in a single function. ", "generate_estimate_discriminate_dm <- function(params) {", 
        "  params %>% ", "    dgp_panel() %>% ", "        demean_data() %>% ", 
        "            estimator_fn_dm() %>% ", "              disc_fn_dm() %>% ", 
        "                data.frame(tau_hat = .) # store the result as a data frame object", 
        "}", "", "M = 100", "result_dm <- ", "  1:M %>% ", "  map_df(~generate_estimate_discriminate_dm(params_panel)) ", 
        "", "plot_sampling_distribution(result_dm$tau_hat, truth = params_panel$tau)", 
        ""), out.width.px = 624, out.height.px = 384, params.src = "demean4,exercise.setup=\"demean3\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-cre1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-cre1-code-editor`)), session)
output$`tutorial-exercise-cre1-output` <- renderUI({
  `tutorial-exercise-cre1-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "cre1", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "cre1", code = "prepare_cre <- function(df) {\n  df %>% \n    group_by(t) %>%\n    mutate(d_bar_t = mean(d_i),\n           x_bar_t = mean(x_i)) %>%\n    group_by(unit_id) %>%\n    mutate(d_bar_i = mean(d_i),\n           x_bar_i = mean(x_i))\n}\n\nestimator_fn_cre <- function(df) {\n  suppressWarnings({suppressMessages({\n    lmer(y_i ~ d_i + d_bar_t + d_bar_i + (1|t) + (1|unit_id), df)\n  })})\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel()  %>% \n    prepare_cre() %>% \n      estimator_fn_cre()\n", 
            opts = list(label = "\"cre1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "25L"), 
            engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "Panel-Data-Methods-I_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "cre1", exercise.setup = "dgp_panel_setup", exercise = TRUE, 
        exercise.lines = 25L, code = c("prepare_cre <- function(df) {", 
        "  df %>% ", "    group_by(t) %>%", "    mutate(d_bar_t = mean(d_i),", 
        "           x_bar_t = mean(x_i)) %>%", "    group_by(unit_id) %>%", 
        "    mutate(d_bar_i = mean(d_i),", "           x_bar_i = mean(x_i))", 
        "}", "", "estimator_fn_cre <- function(df) {", "  suppressWarnings({suppressMessages({", 
        "    lmer(y_i ~ d_i + d_bar_t + d_bar_i + (1|t) + (1|unit_id), df)", 
        "  })})", "}", "", "set.seed(123)", "params_panel %>% ", 
        "  dgp_panel()  %>% ", "    prepare_cre() %>% ", "      estimator_fn_cre()", 
        ""), out.width.px = 624, out.height.px = 384, params.src = "cre1, exercise.setup=\"dgp_panel_setup\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-cre2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-cre2-code-editor`)), session)
output$`tutorial-exercise-cre2-output` <- renderUI({
  `tutorial-exercise-cre2-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "cre2", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n\nprepare_cre <- function(df) {\n  df %>% \n    group_by(t) %>%\n    mutate(d_bar_t = mean(d_i),\n           x_bar_t = mean(x_i)) %>%\n    group_by(unit_id) %>%\n    mutate(d_bar_i = mean(d_i),\n           x_bar_i = mean(x_i))\n}\n\nestimator_fn_cre <- function(df) {\n  suppressWarnings({suppressMessages({\n    lmer(y_i ~ d_i + d_bar_t + d_bar_i + (1|t) + (1|unit_id), df)\n  })})\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel()  %>% \n    prepare_cre() %>% \n      estimator_fn_cre()\n", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "cre1", code = "prepare_cre <- function(df) {\n  df %>% \n    group_by(t) %>%\n    mutate(d_bar_t = mean(d_i),\n           x_bar_t = mean(x_i)) %>%\n    group_by(unit_id) %>%\n    mutate(d_bar_i = mean(d_i),\n           x_bar_i = mean(x_i))\n}\n\nestimator_fn_cre <- function(df) {\n  suppressWarnings({suppressMessages({\n    lmer(y_i ~ d_i + d_bar_t + d_bar_i + (1|t) + (1|unit_id), df)\n  })})\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel()  %>% \n    prepare_cre() %>% \n      estimator_fn_cre()\n", 
            opts = list(label = "\"cre1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "25L"), 
            engine = "r"), list(label = "cre2", code = "estimator_fn_fe <- function(df) {\n  suppressWarnings({suppressMessages({\n    feglm(y_i ~  d_i | t + unit_id, df, family = \"gaussian\")\n  })})\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel()  %>% \n    prepare_cre() %>% \n      estimator_fn_fe()\n", 
            opts = list(label = "\"cre2\"", exercise.setup = "\"cre1\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "13L"), 
            engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "Panel-Data-Methods-I_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "cre2", exercise.setup = "cre1", exercise = TRUE, 
        exercise.lines = 13L, code = c("estimator_fn_fe <- function(df) {", 
        "  suppressWarnings({suppressMessages({", "    feglm(y_i ~  d_i | t + unit_id, df, family = \"gaussian\")", 
        "  })})", "}", "", "set.seed(123)", "params_panel %>% ", 
        "  dgp_panel()  %>% ", "    prepare_cre() %>% ", "      estimator_fn_fe()", 
        ""), out.width.px = 624, out.height.px = 384, params.src = "cre2, exercise.setup=\"cre1\"", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "3"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-cre3-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-cre3-code-editor`)), session)
output$`tutorial-exercise-cre3-output` <- renderUI({
  `tutorial-exercise-cre3-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "cre3", global_setup = structure(c("library(learnr)", 
"knitr::opts_chunk$set(echo = FALSE)", "", "# load packages", 
"library(learnr)", "library(gradethis)", "library(sortable)", 
"library(tidyverse)", "library(learnrhash) #devtools::install_github(\"rundel/learnrhash\")", 
"library(showtext)", "library(googlesheets4)", "library(mcreplicate)", 
"library(knitr)", "library(hrbrthemes)", "library(here)", "library(lme4)", 
"library(progressr)", "library(janitor)", "library(future)", 
"library(fixest)", "library(broom)", "lag <- dplyr::lag", "#devtools::install_github(\"graveja0/HPOL8539PKG\")", 
"#library(HPOL8539PKG)", "# devtools::load_all(\"../../HPOL8539PKG\")", 
"", "", "# don't echo chunks", "knitr::opts_chunk$set(echo = FALSE)", 
"", "# apply theme to ggplot", "ggplot2::theme_set(theme_bw())", 
"", "map_multicore <- function(.x, .f, ..., .id = NULL) {", "  .f <- purrr::as_mapper(.f, ...)", 
"  p <- progressor(steps = length(.x))", "  f <- function(...) {", 
"    p()", "    .f(...)", "  }", "  furrr::future_map(.x, f, ..., .id = .id)", 
"}", "", "plot_sampling_distribution <- function(x,truth) {", 
"  d <- density(x)", "  p_df <- as_tibble(cbind(x = d$x, density = d$y))", 
"  p_df %>%", "    ggplot(aes(x = x, y = density)) + geom_line() +", 
"    #hrbrthemes::theme_ipsum() +", "    labs(x = \"Estimate\", y = \"Density\") +", 
"    geom_vline(aes(xintercept = truth)) +", "    annotate(\"text\",x = mean(x), y = min(d$y*1.2), vjust=-1,label  = glue::glue(\"  \\tMean: {formatC(mean(x),digits = 3, format='f')}\\n   SD: {formatC(sd(x),digits = 3, format = 'f')}\\n   Truth: {truth}\"), hjust = 0)", 
"}", "", "plot_cis <- function(x, K, truth) {", "  res <- x %>% bind_rows(.id = \"m\") %>%", 
"    as_tibble() %>%", "    mutate(m = factor(m)) %>%", "    mutate(m = fct_reorder(m,estimate, .desc = TRUE)) %>%", 
"    mutate(truth = truth) %>%", "    rowwise() %>%", "    mutate(covered = as.integer(between(truth,conf.low,conf.high))) %>%", 
"    ungroup() %>%", "    mutate(color = ifelse(covered ==1 , \"\",\"Rejected\"))", 
"  ", "  K = sample(res$m,100, replace =TRUE)", "  res %>%", 
"    filter(m %in% K) %>%", "    ggplot() +", "    geom_errorbar(aes(xmin =  conf.low, xmax = conf.high, y= m,colour = color)) +", 
"    #theme_ipsum() +", "    scale_y_discrete(breaks = NULL) +", 
"    geom_vline(aes(xintercept = truth)) +", "    labs(title= glue(\"Confidence Intervals for {prettyNum(length(K),big.mark=',')} of {prettyNum(length(res$m),big.mark=',')} Estimates\"),", 
"         y= \"Sampling Iteration\",x = \"Estimate\",", "         subtitle= glue(\"{formatC(100*mean(res$covered),digits = 1, format='f')}% of confidence intervals cover the truth\")) +", 
"    scale_colour_manual(values = c(\"black\",\"red\")) +", "    theme(legend.position = \"none\")", 
"}", "", "options(\"scipen\" = 100, \"digits\" = 5)", "", "#knitr::purl(here(\"Panel Data Methods I/Panel Data Methods I.Rmd\"))"
), chunk_opts = list(label = "setup", include = FALSE)), setup = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n\nprepare_cre <- function(df) {\n  df %>% \n    group_by(t) %>%\n    mutate(d_bar_t = mean(d_i),\n           x_bar_t = mean(x_i)) %>%\n    group_by(unit_id) %>%\n    mutate(d_bar_i = mean(d_i),\n           x_bar_i = mean(x_i))\n}\n\nestimator_fn_cre <- function(df) {\n  suppressWarnings({suppressMessages({\n    lmer(y_i ~ d_i + d_bar_t + d_bar_i + (1|t) + (1|unit_id), df)\n  })})\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel()  %>% \n    prepare_cre() %>% \n      estimator_fn_cre()\n\nestimator_fn_fe <- function(df) {\n  suppressWarnings({suppressMessages({\n    feglm(y_i ~  d_i | t + unit_id, df, family = \"gaussian\")\n  })})\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel()  %>% \n    prepare_cre() %>% \n      estimator_fn_fe()\n", 
    chunks = list(list(label = "dgp_panel_setup", code = "params_panel <- list(\n  N = 1000,\n  T = 2,\n  tx_time = 2, \n  rho_t = 0.8,\n  beta_0 = 0.5,\n  beta_1 = 2,\n  tau = 0.5,\n  p_d = 0.5\n)\n\ndgp_panel <- function(params) {\n  with(params, {\n\n    # Time effects\n    t_ <-\n      data.frame(t = 1:T,\n                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())\n\n    # Individual measures and effects\n    i_ <-\n      data.frame(\n        unit_id = 1:N,\n        x_i = rnorm(N, mean = 0, sd = 1),\n        u_i = rnorm(N, mean = 0, sd = 1)) %>%\n      rowwise() %>% # This allows us to get each value's pr_treated in the line below. \n      mutate(pr_treated = boot::inv.logit(u_i)) %>% \n      ungroup() %>%  # This undoes the rowwise \n      # Treatment indicator\n      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% \n      ungroup()\n\n    crossing(unit_id = i_$unit_id,t = t_$t) %>%\n      left_join(i_,\"unit_id\") %>%\n      left_join(t_,\"t\") %>%\n      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%\n      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1))\n  })\n}\n\nparams_panel %>% \n  dgp_panel()\n", 
        opts = list(label = "\"dgp_panel_setup\"", echo = "TRUE", 
            exercise = "TRUE", exercise.lines = "45L"), engine = "r"), 
        list(label = "cre1", code = "prepare_cre <- function(df) {\n  df %>% \n    group_by(t) %>%\n    mutate(d_bar_t = mean(d_i),\n           x_bar_t = mean(x_i)) %>%\n    group_by(unit_id) %>%\n    mutate(d_bar_i = mean(d_i),\n           x_bar_i = mean(x_i))\n}\n\nestimator_fn_cre <- function(df) {\n  suppressWarnings({suppressMessages({\n    lmer(y_i ~ d_i + d_bar_t + d_bar_i + (1|t) + (1|unit_id), df)\n  })})\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel()  %>% \n    prepare_cre() %>% \n      estimator_fn_cre()\n", 
            opts = list(label = "\"cre1\"", exercise.setup = "\"dgp_panel_setup\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "25L"), 
            engine = "r"), list(label = "cre2", code = "estimator_fn_fe <- function(df) {\n  suppressWarnings({suppressMessages({\n    feglm(y_i ~  d_i | t + unit_id, df, family = \"gaussian\")\n  })})\n}\n\nset.seed(123)\nparams_panel %>% \n  dgp_panel()  %>% \n    prepare_cre() %>% \n      estimator_fn_fe()\n", 
            opts = list(label = "\"cre2\"", exercise.setup = "\"cre1\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "13L"), 
            engine = "r"), list(label = "cre3", code = "disc_fn_cre <- function(fit) {\n  fit %>% summary() %>% pluck(\"coefficients\") %>%\n    data.frame() %>%\n    rownames_to_column() %>%\n    janitor::clean_names() %>%\n    filter(rowname==\"d_i\") %>%\n    pull(estimate) %>%\n    as.vector()\n}\n\ngenerate_estimate_discriminate_cre <- function(params) {\n  params %>% # Step 1: Parameterize the problem\n    dgp_panel() %>%  # Step 2: Define the data generation process\n      prepare_cre() %>% # Step 2.5: Get the unit- and time-specific means \n      estimator_fn_cre() %>%  # Step 3: Estimate \n        disc_fn_cre() %>% # Step 4: Pull out what you need\n        data.frame(tau_hat = .) # store the result as a data frame object\n}\n\n\nM = 100\nresult_cre <- 1:M %>% map_df(~generate_estimate_discriminate_cre(params_panel))\nplot_sampling_distribution(result_cre$tau_hat, truth = params_panel$tau)\n\n\n", 
            opts = list(label = "\"cre3\"", exercise.setup = "\"cre2\"", 
                echo = "TRUE", exercise = "TRUE", exercise.lines = "25L"), 
            engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "Panel-Data-Methods-I_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "Panel-Data-Methods-I_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (label = NULL, solution_code = NULL, user_code = NULL, \n    check_code = NULL, envir_result = NULL, evaluate_result = NULL, \n    envir_prep = NULL, last_value = NULL, stage = NULL, ...) \n{\n    (utils::getFromNamespace(\"check_exercise\", \"gradethis\"))(label = label, \n        solution_code = solution_code, user_code = user_code, \n        check_code = check_code, envir_result = envir_result, \n        evaluate_result = evaluate_result, envir_prep = envir_prep, \n        last_value = last_value, stage = stage, ...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        label = "cre3", exercise.setup = "cre2", exercise = TRUE, 
        exercise.lines = 25L, code = c("disc_fn_cre <- function(fit) {", 
        "  fit %>% summary() %>% pluck(\"coefficients\") %>%", 
        "    data.frame() %>%", "    rownames_to_column() %>%", 
        "    janitor::clean_names() %>%", "    filter(rowname==\"d_i\") %>%", 
        "    pull(estimate) %>%", "    as.vector()", "}", "", 
        "generate_estimate_discriminate_cre <- function(params) {", 
        "  params %>% # Step 1: Parameterize the problem", "    dgp_panel() %>%  # Step 2: Define the data generation process", 
        "      prepare_cre() %>% # Step 2.5: Get the unit- and time-specific means ", 
        "      estimator_fn_cre() %>%  # Step 3: Estimate ", 
        "        disc_fn_cre() %>% # Step 4: Pull out what you need", 
        "        data.frame(tau_hat = .) # store the result as a data frame object", 
        "}", "", "", "M = 100", "result_cre <- 1:M %>% map_df(~generate_estimate_discriminate_cre(params_panel))", 
        "plot_sampling_distribution(result_cre$tau_hat, truth = params_panel$tau)", 
        "", "", ""), out.width.px = 624, out.height.px = 384, 
        params.src = "cre3, exercise.setup=\"cre2\"", fig.num = 0, 
        exercise.df_print = "paged"), engine = "r", version = "3"), class = "tutorial_exercise"))
</script>
</p>
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["header-attrs"]},{"type":"character","attributes":{},"value":["2.16"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pandoc"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["header-attrs.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"character","attributes":{},"value":["<style>h1 {font-size: 34px;}\n       h1.title {font-size: 38px;}\n       h2 {font-size: 30px;}\n       h3 {font-size: 24px;}\n       h4 {font-size: 18px;}\n       h5 {font-size: 16px;}\n       h6 {font-size: 12px;}\n       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}\n       pre:not([class]) { background-color: white }<\/style>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.5.9000"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["i18n"]},{"type":"character","attributes":{},"value":["21.6.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/i18n"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["i18next.min.js","tutorial-i18n-init.js"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["<script id=\"i18n-cstm-trns\" type=\"application/json\">{\"language\":\"en\",\"resources\":{\"en\":{\"translation\":{\"button\":{\"runcode\":\"Run Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Hint\",\"hint_plural\":\"Hints\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Next Hint\",\"hintprev\":\"Previous Hint\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copy to Clipboard\",\"startover\":\"Start Over\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continue\",\"submitanswer\":\"Submit Answer\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Previous Topic\",\"nexttopic\":\"Next Topic\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Try Again\"},\"text\":{\"startover\":\"Start Over\",\"areyousure\":\"Are you sure you want to start over? (all exercise progress will be reset)\",\"youmustcomplete\":\"You must complete the\",\"exercise\":\"exercise\",\"exercise_plural\":\"exercises\",\"inthissection\":\"in this section before continuing.\",\"code\":\"Code\",\"enginecap\":\"{{engine}} $t(text.code)\",\"quiz\":\"Quiz\",\"blank\":\"blank\",\"blank_plural\":\"blanks\",\"exercisecontainsblank\":\"This exercise contains {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Please replace {{blank}} with valid code.\",\"unparsable\":\"It looks like this might not be valid R code. R cannot determine how to turn your text into a complete command. You may have forgotten to fill in a blank, to remove an underscore, to include a comma between arguments, or to close an opening <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> or <code>{<\\/code> with a matching <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> or <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>It looks like your R code contains specially formatted quotation marks or &quot;curly&quot; quotes (<code>{{character}}<\\/code>) around character strings, making your code invalid. R requires character values to be contained in straight quotation marks (<code>&quot;<\\/code> or <code>'<\\/code>).<\\/p> {{code}} <p>Don't worry, this is a common source of errors when you copy code from another app that applies its own formatting to text. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. Try deleting the special character from your code and retyping it manually.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"and\":\"and\",\"or\":\"or\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"fr\":{\"translation\":{\"button\":{\"runcode\":\"Lancer le Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Indication\",\"hint_plural\":\"Indications\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Indication Suivante\",\"hintprev\":\"Indication Précédente\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copier dans le Presse-papier\",\"startover\":\"Recommencer\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuer\",\"submitanswer\":\"Soumettre\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Chapitre Précédent\",\"nexttopic\":\"Chapitre Suivant\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Réessayer\"},\"text\":{\"startover\":\"Recommencer\",\"areyousure\":\"Êtes-vous certains de vouloir recommencer? (La progression sera remise à zéro)\",\"youmustcomplete\":\"Vous devez d'abord compléter\",\"exercise\":\"l'exercice\",\"exercise_plural\":\"des exercices\",\"inthissection\":\"de cette section avec de continuer.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"et\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"es\":{\"translation\":{\"button\":{\"runcode\":\"Ejecutar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Pista\",\"hint_plural\":\"Pistas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Siguiente pista\",\"hintprev\":\"Pista anterior\",\"solution\":\"Solución\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar al portapapeles\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar respuesta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tema anterior\",\"nexttopic\":\"Tema siguiente\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Volver a intentar\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"¿De verdad quieres empezar de nuevo? (todo el progreso del ejercicio se perderá)\",\"youmustcomplete\":\"Debes completar\",\"exercise\":\"el ejercicio\",\"exercise_plural\":\"los ejercicios\",\"inthissection\":\"en esta sección antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Cuestionario\",\"and\":\"y\",\"or\":\"o\",\"oxfordcomma\":\"\"}}},\"pt\":{\"translation\":{\"button\":{\"runcode\":\"Executar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Dica\",\"hint_plural\":\"Dicas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Próxima dica\",\"hintprev\":\"Dica anterior\",\"solution\":\"Solução\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar para a área de transferência\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar resposta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tópico anterior\",\"nexttopic\":\"Próximo tópico\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tentar novamente\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"Tem certeza que deseja começar novamente? (todo o progresso feito será perdido)\",\"youmustcomplete\":\"Você deve completar\",\"exercise\":\"o exercício\",\"exercise_plural\":\"os exercícios\",\"inthissection\":\"nesta seção antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"e\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"tr\":{\"translation\":{\"button\":{\"runcode\":\"Çalıştırma Kodu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Ipucu\",\"hint_plural\":\"İpuçları\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Sonraki İpucu\",\"hintprev\":\"Önceki İpucu\",\"solution\":\"Çözüm\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Pano'ya Kopyala\",\"startover\":\"Baştan Başlamak\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Devam et\",\"submitanswer\":\"Cevabı onayla\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Önceki Konu\",\"nexttopic\":\"Sonraki Konu\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tekrar Deneyin\"},\"text\":{\"startover\":\"Baştan Başlamak\",\"areyousure\":\"Baştan başlamak istediğinizden emin misiniz? (tüm egzersiz ilerlemesi kaybolacak)\",\"youmustcomplete\":\"Tamamlamalısın\",\"exercise\":\"egzersiz\",\"exercise_plural\":\"egzersizler\",\"inthissection\":\"devam etmeden önce bu bölümde\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Sınav\",\"oxfordcomma\":\"\"}}},\"emo\":{\"translation\":{\"button\":{\"runcode\":\"🏃\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"💡\",\"hint_plural\":\"$t(button.hint)\",\"hinttitle\":\"$t(button.hint)\",\"solution\":\"🎯\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"📋\",\"startover\":\"⏮\",\"startovertitle\":\"Start Over\",\"continue\":\"✅\",\"submitanswer\":\"🆗\",\"submitanswertitle\":\"Submit Answer\",\"previoustopic\":\"⬅\",\"nexttopic\":\"➡\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"🔁\"},\"text\":{\"startover\":\"⏮\",\"areyousure\":\"🤔\",\"youmustcomplete\":\"⚠️ 👉 🧑‍💻\",\"exercise\":\"\",\"exercise_plural\":\"\",\"inthissection\":\"\",\"code\":\"💻\",\"enginecap\":\"$t(text.code) {{engine}}\",\"oxfordcomma\":\"\"}}},\"eu\":{\"translation\":{\"button\":{\"runcode\":\"Kodea egikaritu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Laguntza\",\"hint_plural\":\"Laguntza\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Aurreko laguntza\",\"hintprev\":\"Hurrengo laguntza\",\"solution\":\"Ebazpena\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Arbelean kopiatu\",\"startover\":\"Berrabiarazi\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Jarraitu\",\"submitanswer\":\"Erantzuna bidali\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Aurreko atala\",\"nexttopic\":\"Hurrengo atala\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Berriro saiatu\"},\"text\":{\"startover\":\"Berrabiarazi\",\"areyousure\":\"Berriro hasi nahi duzu? (egindako lana galdu egingo da)\",\"youmustcomplete\":\"Aurrera egin baino lehen atal honetako\",\"exercise\":\"ariketa egin behar duzu.\",\"exercise_plural\":\"ariketak egin behar dituzu.\",\"inthissection\":\"\",\"code\":\"Kodea\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Galdetegia\",\"oxfordcomma\":\"\"}}},\"de\":{\"translation\":{\"button\":{\"runcode\":\"Code ausführen\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Tipp\",\"hint_plural\":\"Tipps\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Nächster Tipp\",\"hintprev\":\"Vorheriger Tipp\",\"solution\":\"Lösung\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"In die Zwischenablage kopieren\",\"startover\":\"Neustart\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Weiter\",\"submitanswer\":\"Antwort einreichen\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Vorheriges Kapitel\",\"nexttopic\":\"Nächstes Kapitel\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Nochmal versuchen\"},\"text\":{\"startover\":\"Neustart\",\"areyousure\":\"Bist du sicher, dass du neustarten willst? (der gesamte Lernfortschritt wird gelöscht)\",\"youmustcomplete\":\"Vervollstädinge\",\"exercise\":\"die Übung\",\"exercise_plural\":\"die Übungen\",\"inthissection\":\"in diesem Kapitel, bevor du fortfährst.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"Lücke\",\"blank_plural\":\"Lücken\",\"pleasereplaceblank\":\"Bitte ersetze {{blank}} mit gültigem Code.\",\"unparsable\":\"Dies scheint kein gültiger R Code zu sein. R kann deinen Text nicht in einen gültigen Befehl übersetzen. Du hast vielleicht vergessen, die Lücke zu füllen, einen Unterstrich zu entfernen, ein Komma zwischen Argumente zu setzen oder ein eröffnendes <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> oder <code>{<\\/code> mit einem zugehörigen <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> oder <code>}<\\/code> zu schließen.\\n\",\"and\":\"und\",\"or\":\"oder\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"ko\":{\"translation\":{\"button\":{\"runcode\":\"코드 실행\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"힌트\",\"hint_plural\":\"힌트들\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"다음 힌트\",\"hintprev\":\"이전 힌트\",\"solution\":\"솔루션\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"클립보드에 복사\",\"startover\":\"재학습\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"다음 학습으로\",\"submitanswer\":\"정답 제출\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"이전 토픽\",\"nexttopic\":\"다음 토픽\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"재시도\"},\"text\":{\"startover\":\"재학습\",\"areyousure\":\"다시 시작 하시겠습니까? (모든 예제의 진행 정보가 재설정됩니다)\",\"youmustcomplete\":\"당신은 완료해야 합니다\",\"exercise\":\"연습문제\",\"exercise_plural\":\"연습문제들\",\"inthissection\":\"이 섹션을 실행하기 전에\",\"code\":\"코드\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"퀴즈\",\"blank\":\"공백\",\"blank_plural\":\"공백들\",\"exercisecontainsblank\":\"이 연습문제에는 {{count}}개의 $t(text.blank)이 포함되어 있습니다.\",\"pleasereplaceblank\":\"{{blank}}를 유효한 코드로 바꾸십시오.\",\"unparsable\":\"이것은 유효한 R 코드가 아닐 수 있습니다. R은 텍스트를 완전한 명령으로 변환하는 방법을 결정할 수 없습니다. 당신은 공백이나 밑줄을 대체하여 채우기, 인수를 컴마로 구분하기, 또는 <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> , <code>{<\\/code>로 시작하는 구문을 닫는 <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>, <code>}<\\/code>을 잊었을 수도 있습니다.\\n\",\"and\":\"그리고\",\"or\":\"혹은\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}},\"zh\":{\"translation\":{\"button\":{\"runcode\":\"运行代码\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"提示\",\"hint_plural\":\"提示\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"下一个提示\",\"hintprev\":\"上一个提示\",\"solution\":\"答案\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"复制到剪切板\",\"startover\":\"重新开始\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"继续\",\"submitanswer\":\"提交答案\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"上一专题\",\"nexttopic\":\"下一专题\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"再试一次\"},\"text\":{\"startover\":\"重置\",\"areyousure\":\"你确定要重新开始吗? (所有当前进度将被重置)\",\"youmustcomplete\":\"你必须完成\",\"exercise\":\"练习\",\"exercise_plural\":\"练习\",\"inthissection\":\"在进行本节之前\",\"code\":\"代码\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"测试\",\"blank\":\"空\",\"blank_plural\":\"空\",\"exercisecontainsblank\":\"本练习包含{{count}}个$t(text.blank)\",\"pleasereplaceblank\":\"请在{{blank}}内填写恰当的代码\",\"unparsable\":\"这似乎不是有效的R代码。 R不知道如何将您的文本转换为完整的命令。 您是否忘了填空，忘了删除下划线，忘了在参数之间包含逗号，或者是忘了用<code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>,<code>}<\\/code>来封闭<code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code>。 or <code>{<\\/code>。\\n\",\"unparsablequotes\":\"<p>您的R代码中似乎含有特殊格式的引号，或者弯引号(<code>{{character}}<\\/code>) 在字符串前后，在R中字符串应该被直引号(<code>&quot;<\\/code> 或者 <code>'<\\/code>)包裹。<\\/p> {{code}} <p>别担心，该错误经常在复制粘贴包含格式的代码时遇到， 您可以尝试将该行中的代码替换为以下代码，也许还有其他地方需要修改。<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>您的代码中似乎包含有异常字符(<code>{{character}}<\\/code>),导致代码无效。<\\/p> {{code}} <p>有时候你的代码可能含有看似正常字符的特殊字符，特别是当你复制粘贴其他来源代码的时候。 请试着删除这些特殊字符,重新输入<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>您的代码中似乎包含有异常字符(<code>{{character}}<\\/code>),导致代码无效。<\\/p> {{code}} <p>有时候你的代码可能含有看似正常字符的特殊字符，特别是当你复制粘贴其他来源代码的时候。 请试着删除这些特殊字符,重新输入<\\/p>\\n\",\"and\":\"且\",\"or\":\"或\",\"listcomma\":\",\",\"oxfordcomma\":\",\"}}},\"pl\":{\"translation\":{\"button\":{\"runcode\":\"Uruchom kod\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Podpowiedź\",\"hint_plural\":\"Podpowiedzi\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Następna podpowiedź\",\"hintprev\":\"Poprzednia podpowiedź\",\"solution\":\"Rozwiązanie\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Kopiuj do schowka\",\"startover\":\"Zacznij od początku\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Kontynuuj\",\"submitanswer\":\"Wyślij\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Poprzednia sekcja\",\"nexttopic\":\"Następna sekcja\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Spróbuj ponownie\"},\"text\":{\"startover\":\"Zacznij od początku\",\"areyousure\":\"Czy na pewno chcesz zacząć od początku? (cały postęp w zadaniu zostanie utracony)\",\"youmustcomplete\":\"Musisz ukończyć\",\"exercise\":\"ćwiczenie\",\"exercise_plural\":\"ćwiczenia\",\"inthissection\":\"w tej sekcji przed kontynuowaniem\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"luka\",\"blank_plural\":\"luk(i)\",\"exercisecontainsblank\":\"To ćwiczenie zawiera {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Proszę uzupełnić {{blank}} prawidłowym kodem.\",\"unparsable\":\"Wygląda na to, że może to nie być prawidłowy kod R. R nie jest w stanie przetworzyć Twojego tekstu na polecenie. Mogłeś(-aś) zapomnieć wypełnić luki, usunąć podkreślnik, umieścić przecinka między argumentami, lub zamknąć znak <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> lub <code>{<\\/code> odpowiadającym <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> lub <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>Wygląda na to, że Twój kod zawiera szczególnie sformatowane cudzysłowy lub cudzysłowy typograficzne (<code>{{character}}<\\/code>) przy ciągach znaków, co sprawia, że kod jest niepoprawny. R wymaga cudzysłowów prostych (<code>&quot;<\\/code> albo <code>'<\\/code>).<\\/p> {{code}} <p>Nie martw się, to powszechne źródło błędów, gdy kopiuje się kod z innego programu, który sam formatuje teskt. Możesz spróbować zastąpić swój kod następującym kodem. Mogą być też inne miejsca, które wymagają poprawienia.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>Wygląda na to, że Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, że kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod może zawierać znak specjalny, który wygląda jak zwykły znak, zwłaszcza jeśli kopiujesz kod z innego programu. Spróbuj usunąć znak specjalny i wpisać do ponownie ręcznie.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>Wygląda na to, że Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, że kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod może zawierać znak specjalny, który wygląda jak zwykły znak, zwłaszcza jeśli kopiujesz kod z innego programu. Możesz spróbować zastąpić swój kod następującym kodem. Mogą być też inne miejsca, które wymagają poprawienia.<\\/p> {{suggestion}}\\n\",\"and\":\"i\",\"or\":\"lub\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}}}}<\/script>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.10.5.9000"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["5.5.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.5.9000"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.5.9000"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126]}},"value":[{"type":"character","attributes":{},"value":["assertthat","backports","base","boot","broom","bslib","cachem","cellranger","checkmate","cli","codetools","colorspace","compiler","crayon","curl","datasets","DBI","dbplyr","digest","dplyr","dreamerr","ellipsis","evaluate","extrafont","extrafontdb","fansi","fastmap","fixest","forcats","Formula","fs","future","gargle","gdtools","generics","ggplot2","globals","glue","googledrive","googlesheets4","gradethis","graphics","grDevices","grid","gtable","haven","here","highr","hms","hrbrthemes","htmltools","htmlwidgets","httpuv","httr","janitor","jquerylib","jsonlite","knitr","later","lattice","learnr","learnrhash","lifecycle","listenv","lme4","lubridate","magrittr","markdown","MASS","Matrix","mcreplicate","methods","mime","minqa","modelr","munsell","nlme","nloptr","numDeriv","parallel","parallelly","pillar","pkgconfig","progressr","promises","purrr","R6","Rcpp","readr","readxl","reprex","rlang","rmarkdown","rprojroot","rstudioapi","Rttf2pt1","rvest","sandwich","sass","scales","shiny","showtext","showtextdb","snakecase","sortable","splines","stats","stringi","stringr","sysfonts","systemfonts","tibble","tidyr","tidyselect","tidyverse","tools","tzdb","utf8","utils","vctrs","withr","xfun","xml2","xtable","yaml","zoo"]},{"type":"character","attributes":{},"value":["0.2.1","1.4.1","4.2.1","1.3-28","1.0.0","0.4.0","1.0.6","1.1.0","2.1.0","3.3.0","0.2-18","2.0-3","4.2.1","1.5.1","4.3.2","4.2.1","1.1.3","2.2.1","0.6.29","1.0.9","1.2.3","0.3.2","0.16","0.18","1.0","1.0.3","1.1.0","0.10.4","0.5.2","1.2-4","1.5.2","1.27.0","1.2.0","0.2.4","0.1.3","3.3.6","0.16.0","1.6.2","2.0.0","1.0.1","0.2.8.9000","4.2.1","4.2.1","4.2.1","0.3.0","2.5.1","1.0.1","0.9","1.1.2","0.8.0","0.5.3","1.5.4","1.6.5","1.4.4","2.1.0","0.1.4","1.8.0","1.40","1.3.0","0.20-45","0.10.5.9000","0.2.0","1.0.1","0.8.0","1.1-30","1.8.0","2.0.3","1.1","7.3-58.1","1.4-1","0.1.2","4.2.1","0.12","1.2.4","0.1.9","0.5.0","3.1-159","2.0.3","2016.8-1.1","4.2.1","1.32.1","1.8.1","2.0.3","0.11.0","1.2.0.1","0.3.4","2.5.1","1.0.9","2.1.2","1.4.1","2.0.2","1.0.4","2.16","2.0.3","0.14","1.3.10","1.0.3","3.0-2","0.4.2","1.2.1","1.7.2","0.9-5","3.0","0.11.0","0.4.6","4.2.1","4.2.1","1.7.8","1.4.1","0.8.8","1.0.4","3.1.8","1.2.0","1.1.2","1.3.2","4.2.1","0.3.0","1.2.2","4.2.1","0.4.1","2.5.0","0.32","1.3.3","1.8-4","2.3.5","1.8-10"]}]}]}
</script>
<!--/html_preserve-->
</div>

</article> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h1 class="title toc-ignore" style="display:none;">Panel Data Methods 1:
Fixed, Random and Correlated Random Effects</h1>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</main> <!-- bandContent page -->
</div> <!-- pageContent band -->



<!-- Build Tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
